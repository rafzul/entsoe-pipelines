{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buat pandasrawclient yang bentuknya dah langsung table data \n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from google.oauth2 import service_account\n",
    "import xmltodict\n",
    "import json\n",
    "import pandas as pd \n",
    "from requests import request\n",
    "import pytz\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Dict\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import csv\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType, BooleanType, TimestampType\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, DataType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from entsoe import EntsoeRawClient\n",
    "from entsoe import EntsoePandasClient\n",
    "\n",
    "\n",
    "#load env variables\n",
    "load_dotenv('./creds/.env', verbose=True, override=True)\n",
    "os.environ['TZ'] = 'UTC'\n",
    "\n",
    "'''\n",
    "----------------\n",
    "INIT VARIABLES\n",
    "----------------\n",
    "'''\n",
    "\n",
    "#setting up entsoe variables\n",
    "security_token = os.environ.get(\"SECURITY_TOKEN\")\n",
    "ENTSOE_URL = 'https://transparency.entsoe.eu/api'\n",
    "\n",
    "#setting up GCP variables\n",
    "service_account_file = os.environ.get(\"SERVICE_ACCOUNT_FILE\")\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    service_account_file\n",
    ")\n",
    "gcs_bucket = os.environ.get(\"CLOUD_STORAGE_BUCKET\")\n",
    "\n",
    "#setting up session\n",
    "entsoe_client = EntsoeRawClient(security_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "----------------\n",
    "SETTING UP FUNCTION CALLS \n",
    "----------------\n",
    "'''\n",
    "\n",
    "# upload data to GCS\n",
    "def upload_blob_to_gcs(bucket_name, contents, destination_blob_name):\n",
    "    # Upload file to bucket\"\"\"\n",
    "\n",
    "    # ID of GCS bucket\n",
    "    # bucket_name =\n",
    "\n",
    "    # the contents from memory to be uploaded to file\n",
    "    # contents =\n",
    "\n",
    "    # the ID of your GCS object\n",
    "    # destination_blob_name =\n",
    "\n",
    "    storage_client = storage.Client(credentials=credentials)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_string(contents)\n",
    "\n",
    "\n",
    "'''\n",
    "----------------\n",
    "EXTRACTION\n",
    "----------------\n",
    "'''\n",
    "#for test, we'll be querying\n",
    "\n",
    "start=pd.Timestamp('202101010000', tz='Europe/Berlin')\n",
    "end=pd.Timestamp('202101010600', tz='Europe/Berlin')\n",
    "country_code= 'DE_TENNET'\n",
    "country_code_from=''\n",
    "country_code_to=''\n",
    "type_marketagreement_type=''\n",
    "contract_marketagreement_type=''\n",
    "label_data='total_generation'\n",
    "\n",
    "actual_start = start + pd.Timedelta(hours=1)\n",
    "actual_end = end + pd.Timedelta(hours=1)\n",
    "\n",
    "try:\n",
    "    entsoe_data = entsoe_client.query_generation(country_code, start=actual_start, end=actual_end)\n",
    "    entsoe_dict = xmltodict.parse(entsoe_data)\n",
    "    #if header is already correct, header = True. if not, header = entsoe_header_list\n",
    "    entsoe_json = json.dumps(entsoe_dict)\n",
    "except Exception as e:\n",
    "    print(\"An exception occurred:\", e)\n",
    "\n",
    "\n",
    "'''\n",
    "----------------\n",
    "LOAD\n",
    "----------------\n",
    "'''\n",
    "#upload to GCS\n",
    "start = start.strftime(\"%Y%m%d%H%M%S\")\n",
    "end = end.strftime(\"%Y%m%d%H%M%S\")\n",
    "landing_filename=f\"{label_data}__{country_code}__{start}__{end}.json\"\n",
    "upload_blob_to_gcs(bucket_name=gcs_bucket, contents=entsoe_json, destination_blob_name=landing_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/09 07:21:15 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.18.27 instead (on interface wlp58s0)\n",
      "23/01/09 07:21:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/01/09 07:21:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# path =\"/home/rafzul/projects/entsoe-pipelines/sample.xml\"\n",
    "\n",
    "#coba spark gcs connector\n",
    "#setup sparksession for entry point - COBA GCS CONNECTOR\n",
    "SPARK_HOME = os.environ[\"SPARK_HOME\"]\n",
    "spark = SparkSession.builder.appName(\"gcp_playground\") \\\n",
    "    .config(\"spark.jars\", f\"{SPARK_HOME}/jars/gcs-connector-hadoop3-latest.jar, {SPARK_HOME}/jars/spark-bigquery-with-dependencies_2.13-0.27.1.jar\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\") \\\n",
    "    .config(\"spark.hadoop.fs.AbstractFileSystem.gs.impl\", \"google.cloud.hadoop.fs.gcs.GoogleHadoopFS\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", service_account_file) \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def download_blob_from_gcs(bucket_name, source_blob_name, local_source_blob_name):\n",
    "#     # Upload file to bucket\"\"\"\n",
    "\n",
    "#     # ID of GCS bucket\n",
    "#     # bucket_name =\n",
    "\n",
    "#     # the contents from memory to be uploaded to file\n",
    "#     # contents =\n",
    "\n",
    "#     # the ID of your GCS object\n",
    "#     # destination_blob_name =\n",
    "\n",
    "#     storage_client = storage.Client(credentials=credentials)\n",
    "#     bucket = storage_client.bucket(bucket_name)\n",
    "#     blob = bucket.blob(source_blob_name)\n",
    "\n",
    "#     blob.download_to_filename(local_source_blob_name)\n",
    "    \n",
    "# #ambil schema\n",
    "# raw_schema_filename = f\"{label_data}__rawschema.txt\"\n",
    "# source_rawschema_filename = f\"schema_source/{raw_schema_filename}\"\n",
    "# local_rawschema_filename = f\"/home/rafzul/projects/entsoe-pipelines/schemas/source/{raw_schema_filename}\"\n",
    "# download_blob_from_gcs(bucket_name=gcs_bucket, source_blob_name=source_rawschema_filename, local_source_blob_name=local_rawschema_filename)\n",
    "\n",
    "# #setting up schema - block\n",
    "\n",
    "# with open(local_rawschema_filename, \"r\") as local_source:\n",
    "#     rawschema_data = local_source.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://entsoe_analytics_1009/total_generation__DE_TENNET__20210101000000__20210101060000.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# berangkat pak haji\n",
    "# setup parameternya\n",
    "gcs_bucket = gcs_bucket\n",
    "path = f\"gs://{gcs_bucket}/{landing_filename}\"\n",
    "print(path)\n",
    "\n",
    "try: \n",
    "   df_spark = spark.read.format(\"json\") \\\n",
    "      .option(\"inferSchema\",\"true\") \\\n",
    "      .option(\"multiLine\",\"true\") \\\n",
    "      .load(path)\n",
    "except Exception as e:\n",
    "   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning column names & casting data type\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "#cleaning documents\n",
    "\n",
    "def clean_columns_n_casttypes(df, parent_column_name):\n",
    "    #cleaning the dots, changed it into namespaces, casting new columns names\n",
    "    df_schema = df.select(parent_column_name).dtypes[0][1]\n",
    "    replacements = [('\\.', '_'), ('[@#]', '')]\n",
    "    for old, new in replacements: \n",
    "        df_schema = re.sub(old, new, df_schema)\n",
    "    #casting the DF with the cleaned schema (must be done first before column name got changed)\n",
    "    df = df.withColumn(parent_column_name, F.col(parent_column_name).cast(df_schema)).select(f\"{parent_column_name}.*\")\n",
    "    # #casting the DF with correct datatype schema, selecting the column inside the big parent column name\n",
    "    # df = df.withColumn(parent_column_name, F.col(parent_column_name).cast(raw_schema))\n",
    "    return df\n",
    "\n",
    "# define flatten struct function\n",
    "def flatten_struct(nested_struct_df): \n",
    "    flat_cols = [c[0] for c in nested_struct_df.dtypes if c[1][:6] != 'struct']\n",
    "    nested_struct_cols = [c[0] for c in nested_struct_df.dtypes if c[1][:6] == 'struct']\n",
    "    flat_df = nested_struct_df.select(flat_cols + [F.col(f\"{nc}.{c}\").alias(f\"{nc}_{c}\") for nc in nested_struct_cols for c in nested_struct_df.select(f\"{nc}.*\").columns])\n",
    "    return flat_df\n",
    "\n",
    "#Extraction from Non TS\n",
    "\n",
    "if label_data in [\"total_generation\"]:\n",
    "    document_column = \"GL_MarketDocument\"\n",
    "df_spark = clean_columns_n_casttypes(df_spark, document_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- xmlns: string (nullable = true)\n",
      " |-- createdDateTime: timestamp (nullable = true)\n",
      " |-- mRID: string (nullable = true)\n",
      " |-- process_processType: string (nullable = true)\n",
      " |-- receiver_MarketParticipant_marketRole_type: string (nullable = true)\n",
      " |-- revisionNumber: string (nullable = true)\n",
      " |-- sender_MarketParticipant_marketRole_type: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- receiver_MarketParticipant_mRID_text: string (nullable = true)\n",
      " |-- receiver_MarketParticipant_mRID_codingScheme: string (nullable = true)\n",
      " |-- sender_MarketParticipant_mRID_text: string (nullable = true)\n",
      " |-- sender_MarketParticipant_mRID_codingScheme: string (nullable = true)\n",
      " |-- time_Period_timeInterval_end: timestamp (nullable = true)\n",
      " |-- time_Period_timeInterval_start: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+-------------------+------------------------------------------+--------------+----------------------------------------+----+------------------------------------+--------------------------------------------+----------------------------------+------------------------------------------+----------------------------+------------------------------+\n",
      "|               xmlns|    createdDateTime|                mRID|process_processType|receiver_MarketParticipant_marketRole_type|revisionNumber|sender_MarketParticipant_marketRole_type|type|receiver_MarketParticipant_mRID_text|receiver_MarketParticipant_mRID_codingScheme|sender_MarketParticipant_mRID_text|sender_MarketParticipant_mRID_codingScheme|time_Period_timeInterval_end|time_Period_timeInterval_start|\n",
      "+--------------------+-------------------+--------------------+-------------------+------------------------------------------+--------------+----------------------------------------+----+------------------------------------+--------------------------------------------+----------------------------------+------------------------------------------+----------------------------+------------------------------+\n",
      "|urn:iec62325.351:...|2023-01-09 07:20:05|20de8f2429984083a...|                A16|                                       A33|             1|                                     A32| A75|                    10X1001A1001A450|                                         A01|                  10X1001A1001A450|                                       A01|         2021-01-01 06:00:00|           2021-01-01 00:00:00|\n",
      "+--------------------+-------------------+--------------------+-------------------+------------------------------------------+--------------+----------------------------------------+----+------------------------------------+--------------------------------------------+----------------------------------+------------------------------------------+----------------------------+------------------------------+\n",
      "\n",
      "root\n",
      " |-- businessType: string (nullable = true)\n",
      " |-- curveType: string (nullable = true)\n",
      " |-- mRID: string (nullable = true)\n",
      " |-- objectAggregation: string (nullable = true)\n",
      " |-- quantity_Measure_Unit_name: string (nullable = true)\n",
      " |-- MktPSRType_psrType: string (nullable = true)\n",
      " |-- Period_Point: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- position: string (nullable = true)\n",
      " |    |    |-- quantity: string (nullable = true)\n",
      " |-- Period_resolution: string (nullable = true)\n",
      " |-- inBiddingZone_Domain_mRID_text: string (nullable = true)\n",
      " |-- inBiddingZone_Domain_mRID_codingScheme: string (nullable = true)\n",
      " |-- outBiddingZone_Domain_mRID_text: string (nullable = true)\n",
      " |-- outBiddingZone_Domain_mRID_codingScheme: string (nullable = true)\n",
      " |-- Period_timeInterval_end: string (nullable = true)\n",
      " |-- Period_timeInterval_start: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#separate df into ts and non ts df\n",
    "df_ts = df_spark.select(\"TimeSeries\")\n",
    "df_nonts = df_spark.drop(\"TimeSeries\")\n",
    "\n",
    "#processing non TS dataframe\n",
    "df_nonts = flatten_struct(flatten_struct(df_nonts))\n",
    "\n",
    "#cast the timestamp column to timestamp type\n",
    "df_nonts = df_nonts.withColumn(\"time_Period_timeInterval_end\", F.to_timestamp(\"time_Period_timeInterval_end\",  \"yyyy-MM-dd'T'HH:mm'Z'\")) \\\n",
    "            .withColumn(\"time_Period_timeInterval_start\", F.to_timestamp(\"time_Period_timeInterval_start\",  \"yyyy-MM-dd'T'HH:mm'Z'\")) \\\n",
    "            .withColumn(\"createdDateTime\", F.to_timestamp(\"createdDateTime\",  \"yyyy-MM-dd'T'HH:mm:ss'Z'\"))\n",
    "df_nonts.printSchema()\n",
    "df_nonts.show()\n",
    "\n",
    "##processing TS dataframe\n",
    "# explode timeseries column into struct, jadiin semua elemen di dalam array TimeSeries jadi satu row\n",
    "df_ts = df_ts.withColumn(\"TimeSeries\", F.explode(\"TimeSeries\"))\n",
    "df_ts = df_ts.select(\"TimeSeries.*\")\n",
    "#flatten nested struct sampe ke dalem, nyisain si period \n",
    "df_ts = flatten_struct(flatten_struct(df_ts))\n",
    "df_ts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+-------------------+------------------------------------------+--------------+----------------------------------------+----+------------------------------------+--------------------------------------------+----------------------------------+------------------------------------------+----------------------------+------------------------------+\n",
      "|               xmlns|    createdDateTime|                mRID|process_processType|receiver_MarketParticipant_marketRole_type|revisionNumber|sender_MarketParticipant_marketRole_type|type|receiver_MarketParticipant_mRID_text|receiver_MarketParticipant_mRID_codingScheme|sender_MarketParticipant_mRID_text|sender_MarketParticipant_mRID_codingScheme|time_Period_timeInterval_end|time_Period_timeInterval_start|\n",
      "+--------------------+-------------------+--------------------+-------------------+------------------------------------------+--------------+----------------------------------------+----+------------------------------------+--------------------------------------------+----------------------------------+------------------------------------------+----------------------------+------------------------------+\n",
      "|urn:iec62325.351:...|2023-01-08 05:21:45|09eb0d8ef92e45069...|                A16|                                       A33|             1|                                     A32| A75|                    10X1001A1001A450|                                         A01|                  10X1001A1001A450|                                       A01|         2021-01-01 05:00:00|           2020-12-31 23:00:00|\n",
      "+--------------------+-------------------+--------------------+-------------------+------------------------------------------+--------------+----------------------------------------+----+------------------------------------+--------------------------------------------+----------------------------------+------------------------------------------+----------------------------+------------------------------+\n",
      "\n",
      "+------------+---------+----+-----------------+--------------------------+------------------+--------------------+-----------------+------------------------------+--------------------------------------+-------------------------------+---------------------------------------+-----------------------+-------------------------+\n",
      "|businessType|curveType|mRID|objectAggregation|quantity_Measure_Unit_name|MktPSRType_psrType|        Period_Point|Period_resolution|inBiddingZone_Domain_mRID_text|inBiddingZone_Domain_mRID_codingScheme|outBiddingZone_Domain_mRID_text|outBiddingZone_Domain_mRID_codingScheme|Period_timeInterval_end|Period_timeInterval_start|\n",
      "+------------+---------+----+-----------------+--------------------------+------------------+--------------------+-----------------+------------------------------+--------------------------------------+-------------------------------+---------------------------------------+-----------------------+-------------------------+\n",
      "|         A01|      A01|   1|              A08|                       MAW|               B01|[{1, 2120}, {2, 2...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|   2|              A08|                       MAW|               B02|[{1, 20}, {2, 20}...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|   3|              A08|                       MAW|               B04|[{1, 1649}, {2, 1...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|   4|              A08|                       MAW|               B05|[{1, 1132}, {2, 9...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|   5|              A08|                       MAW|               B06|[{1, 0}, {2, 0}, ...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|   6|              A08|                       MAW|               B09|[{1, 26}, {2, 26}...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|   7|              A08|                       MAW|               B10|[{1, 0}, {2, 0}, ...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|   8|              A08|                       MAW|               B10|[{1, 228}, {2, 23...|            PT15M|                          null|                                  null|               10YDE-EON------1|                                    A01|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|   9|              A08|                       MAW|               B11|[{1, 502}, {2, 50...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|  10|              A08|                       MAW|               B12|[{1, 16}, {2, 10}...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|  11|              A08|                       MAW|               B14|[{1, 4153}, {2, 4...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|  12|              A08|                       MAW|               B20|[{1, 20}, {2, 20}...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|  13|              A08|                       MAW|               B15|[{1, 10}, {2, 10}...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A94|      A01|  14|              A08|                       MAW|               B16|[{1, 0}, {2, 0}, ...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A01|      A01|  15|              A08|                       MAW|               B17|[{1, 322}, {2, 32...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A93|      A01|  16|              A08|                       MAW|               B18|[{1, 119}, {2, 11...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "|         A93|      A01|  17|              A08|                       MAW|               B19|[{1, 2034}, {2, 1...|            PT15M|              10YDE-EON------1|                                   A01|                           null|                                   null|      2021-01-01T05:00Z|        2020-12-31T23:00Z|\n",
      "+------------+---------+----+-----------------+--------------------------+------------------+--------------------+-----------------+------------------------------+--------------------------------------+-------------------------------+---------------------------------------+-----------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_nonts.show()\n",
    "df_ts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSRTYPE_MAPPINGS = {\n",
    "    'A03': 'Mixed',\n",
    "    'A04': 'Generation',\n",
    "    'A05': 'Load',\n",
    "    'B01': 'Biomass',\n",
    "    'B02': 'Fossil Brown coal/Lignite',\n",
    "    'B03': 'Fossil Coal-derived gas',\n",
    "    'B04': 'Fossil Gas',\n",
    "    'B05': 'Fossil Hard coal',\n",
    "    'B06': 'Fossil Oil',\n",
    "    'B07': 'Fossil Oil shale',\n",
    "    'B08': 'Fossil Peat',\n",
    "    'B09': 'Geothermal',\n",
    "    'B10': 'Hydro Pumped Storage',\n",
    "    'B11': 'Hydro Run-of-river and poundage',\n",
    "    'B12': 'Hydro Water Reservoir',\n",
    "    'B13': 'Marine',\n",
    "    'B14': 'Nuclear',\n",
    "    'B15': 'Other renewable',\n",
    "    'B16': 'Solar',\n",
    "    'B17': 'Waste',\n",
    "    'B18': 'Wind Offshore',\n",
    "    'B19': 'Wind Onshore',\n",
    "    'B20': 'Other',\n",
    "    'B21': 'AC Link',\n",
    "    'B22': 'DC Link',\n",
    "    'B23': 'Substation',\n",
    "    'B24': 'Transformer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|           ts_index|position|\n",
      "+-------------------+--------+\n",
      "|2021-01-01 00:00:00|       1|\n",
      "|2021-01-01 00:15:00|       2|\n",
      "|2021-01-01 00:30:00|       3|\n",
      "|2021-01-01 00:45:00|       4|\n",
      "|2021-01-01 01:00:00|       5|\n",
      "|2021-01-01 01:15:00|       6|\n",
      "|2021-01-01 01:30:00|       7|\n",
      "|2021-01-01 01:45:00|       8|\n",
      "|2021-01-01 02:00:00|       9|\n",
      "|2021-01-01 02:15:00|      10|\n",
      "|2021-01-01 02:30:00|      11|\n",
      "|2021-01-01 02:45:00|      12|\n",
      "|2021-01-01 03:00:00|      13|\n",
      "|2021-01-01 03:15:00|      14|\n",
      "|2021-01-01 03:30:00|      15|\n",
      "|2021-01-01 03:45:00|      16|\n",
      "|2021-01-01 04:00:00|      17|\n",
      "|2021-01-01 04:15:00|      18|\n",
      "|2021-01-01 04:30:00|      19|\n",
      "|2021-01-01 04:45:00|      20|\n",
      "+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n",
      "ts berhasil diparse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------------+---------------------------------------------+------------------------------+------------------------------------+------------------------------+------------------------------+----------------------------------------+-----------------------------------------+---------------------------------------------------+-----------------------------------------+---------------------------+-------------------------+-----------------------------------+-------------------------+-------------------------+---------------------------------+--------------------------------+\n",
      "|           ts_index|Biomass - Actual Aggregated|Fossil Brown coal/Lignite - Actual Aggregated|Fossil Gas - Actual Aggregated|Fossil Hard coal - Actual Aggregated|Fossil Oil - Actual Aggregated|Geothermal - Actual Aggregated|Hydro Pumped Storage - Actual Aggregated|Hydro Pumped Storage - Actual Consumption|Hydro Run-of-river and poundage - Actual Aggregated|Hydro Water Reservoir - Actual Aggregated|Nuclear - Actual Aggregated|Other - Actual Aggregated|Other renewable - Actual Aggregated|Solar - Actual Aggregated|Waste - Actual Aggregated|Wind Offshore - Actual Aggregated|Wind Onshore - Actual Aggregated|\n",
      "+-------------------+---------------------------+---------------------------------------------+------------------------------+------------------------------------+------------------------------+------------------------------+----------------------------------------+-----------------------------------------+---------------------------------------------------+-----------------------------------------+---------------------------+-------------------------+-----------------------------------+-------------------------+-------------------------+---------------------------------+--------------------------------+\n",
      "|2021-01-01 00:00:00|                     2106.0|                                         20.0|                        1405.0|                               677.0|                           0.0|                          26.0|                                     0.0|                                    271.0|                                              506.0|                                     22.0|                     4164.0|                     20.0|                               10.0|                      0.0|                    322.0|                            150.0|                          1738.0|\n",
      "|2021-01-01 00:15:00|                     2105.0|                                         20.0|                        1321.0|                               565.0|                           0.0|                          26.0|                                     0.0|                                     72.0|                                              504.0|                                     14.0|                     4163.0|                     20.0|                               10.0|                      0.0|                    322.0|                            140.0|                          1685.0|\n",
      "|2021-01-01 00:30:00|                     2104.0|                                         20.0|                        1318.0|                               500.0|                           0.0|                          26.0|                                     0.0|                                     78.0|                                              498.0|                                     13.0|                     4168.0|                     20.0|                               10.0|                      0.0|                    322.0|                            114.0|                          1619.0|\n",
      "|2021-01-01 00:45:00|                     2104.0|                                         20.0|                        1317.0|                               500.0|                           0.0|                          26.0|                                     0.0|                                     86.0|                                              494.0|                                     17.0|                     4169.0|                     20.0|                               10.0|                      0.0|                    322.0|                            104.0|                          1556.0|\n",
      "|2021-01-01 01:00:00|                     2097.0|                                         20.0|                        1305.0|                               501.0|                           0.0|                          26.0|                                   337.0|                                      0.0|                                              489.0|                                     20.0|                     4169.0|                     20.0|                               10.0|                      0.0|                    322.0|                             87.0|                          1494.0|\n",
      "|2021-01-01 01:15:00|                     2096.0|                                         20.0|                        1307.0|                               501.0|                           0.0|                          26.0|                                    72.0|                                      3.0|                                              487.0|                                     10.0|                     4178.0|                     20.0|                               10.0|                      0.0|                    322.0|                             98.0|                          1440.0|\n",
      "|2021-01-01 01:30:00|                     2093.0|                                         20.0|                        1307.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    253.0|                                              486.0|                                     16.0|                     4174.0|                     20.0|                               10.0|                      0.0|                    322.0|                            106.0|                          1376.0|\n",
      "|2021-01-01 01:45:00|                     2088.0|                                         20.0|                        1307.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    271.0|                                              484.0|                                     12.0|                     4168.0|                     20.0|                               10.0|                      0.0|                    322.0|                            114.0|                          1287.0|\n",
      "|2021-01-01 02:00:00|                     2083.0|                                         20.0|                        1321.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    324.0|                                              481.0|                                     13.0|                     4159.0|                     20.0|                               10.0|                      0.0|                    322.0|                            123.0|                          1217.0|\n",
      "|2021-01-01 02:15:00|                     2082.0|                                         20.0|                        1321.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    464.0|                                              481.0|                                      8.0|                     4173.0|                     20.0|                               10.0|                      0.0|                    322.0|                            129.0|                          1141.0|\n",
      "|2021-01-01 02:30:00|                     2079.0|                                         20.0|                        1321.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    712.0|                                              482.0|                                      8.0|                     4172.0|                     20.0|                               10.0|                      0.0|                    322.0|                            129.0|                          1076.0|\n",
      "|2021-01-01 02:45:00|                     2073.0|                                         20.0|                        1321.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    704.0|                                              482.0|                                      5.0|                     4170.0|                     20.0|                               10.0|                      0.0|                    322.0|                            133.0|                          1061.0|\n",
      "|2021-01-01 03:00:00|                     2079.0|                                         20.0|                        1345.0|                               505.0|                           0.0|                          26.0|                                     0.0|                                    847.0|                                              482.0|                                     11.0|                     4166.0|                     20.0|                               10.0|                      0.0|                    322.0|                            102.0|                          1050.0|\n",
      "|2021-01-01 03:15:00|                     2082.0|                                         20.0|                        1345.0|                               505.0|                           0.0|                          26.0|                                     0.0|                                    720.0|                                              482.0|                                     10.0|                     4166.0|                     20.0|                               10.0|                      0.0|                    322.0|                             86.0|                          1014.0|\n",
      "|2021-01-01 03:30:00|                     2077.0|                                         20.0|                        1350.0|                               505.0|                           0.0|                          26.0|                                     0.0|                                    745.0|                                              481.0|                                      8.0|                     4157.0|                     20.0|                               10.0|                      0.0|                    322.0|                             87.0|                           998.0|\n",
      "|2021-01-01 03:45:00|                     2079.0|                                         20.0|                        1350.0|                               506.0|                           0.0|                          26.0|                                     0.0|                                    786.0|                                              478.0|                                      7.0|                     4158.0|                     20.0|                               10.0|                      0.0|                    322.0|                            106.0|                           971.0|\n",
      "|2021-01-01 04:00:00|                     2091.0|                                         20.0|                        1419.0|                               511.0|                           0.0|                          25.0|                                     0.0|                                    763.0|                                              474.0|                                      7.0|                     4167.0|                     20.0|                               10.0|                      0.0|                    322.0|                            139.0|                           956.0|\n",
      "|2021-01-01 04:15:00|                     2098.0|                                         20.0|                        1419.0|                               512.0|                           0.0|                          25.0|                                     0.0|                                    773.0|                                              472.0|                                      8.0|                     4156.0|                     20.0|                               10.0|                      0.0|                    322.0|                            167.0|                           931.0|\n",
      "|2021-01-01 04:30:00|                     2096.0|                                         20.0|                        1419.0|                               513.0|                           0.0|                          25.0|                                     0.0|                                    808.0|                                              471.0|                                      8.0|                     4155.0|                     20.0|                               10.0|                      0.0|                    322.0|                            196.0|                           909.0|\n",
      "|2021-01-01 04:45:00|                     2093.0|                                         20.0|                        1419.0|                               514.0|                           0.0|                          25.0|                                     0.0|                                    808.0|                                              472.0|                                      8.0|                     4166.0|                     20.0|                               10.0|                      0.0|                    322.0|                            209.0|                           860.0|\n",
      "+-------------------+---------------------------+---------------------------------------------+------------------------------+------------------------------------+------------------------------+------------------------------+----------------------------------------+-----------------------------------------+---------------------------------------------------+-----------------------------------------+---------------------------+-------------------------+-----------------------------------+-------------------------+-------------------------+---------------------------------+--------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _parse_resolution_to_timedelta(resolution_column: str) -> str:\n",
    "    resolutions = {\n",
    "        'PT60M': 'INTERVAL 1 HOUR',\n",
    "        'P1Y': 'INTERVAL 12 MONTH',\n",
    "        'PT15M': 'INTERVAL 15 MINUTES',\n",
    "        'PT30M': 'INTERVAL 30 MINUTES',\n",
    "        'P1D': 'INTERVAL 1 DAY',\n",
    "        'P7D': 'INTERVAL 7 DAY',\n",
    "        'P1M': 'INTERVAL 1 MONTH',\n",
    "    }\n",
    "    delta = resolutions.get(resolution_column)\n",
    "    if delta is None:\n",
    "        raise NotImplementedError(f\"Sorry, I don't know what to do with the \"\n",
    "                                  \"resolution '{resolution_column}', because there was no \"\n",
    "                                  \"documentation to be found of this format. \"\n",
    "                                  \"Everything is hard coded. Please open an \"\n",
    "                                  \"issue.\")\n",
    "    return delta\n",
    "    \n",
    "#parsing datetime\n",
    "def _parse_datetimeindex(df_ts, df_nonts, tz=None):\n",
    "    start = df_nonts.select(F.col(\"time_Period_timeInterval_start\")).collect()[0][0]\n",
    "    end = df_nonts.select(F.col(\"time_Period_timeInterval_end\")).collect()[0][0]\n",
    "    if tz is not None:\n",
    "        start = df_nonts.select(F.from_utc_timestamp(F.col(\"time_Period_timeInterval_start\"), tz)).collect[0][0]\n",
    "        end = df_nonts.select(F.from_utc_timestamp(F.col(\"time_Period_timeInterval_end\"), tz)).collect()[0][0]\n",
    "    \n",
    "    # ambil resolution dan parse\n",
    "    resolution_col = df_ts.select(F.col(\"Period_resolution\")).collect()[0][0]\n",
    "    delta = _parse_resolution_to_timedelta(resolution_col)\n",
    "\n",
    "    #generate date index\n",
    "    date_index = spark.createDataFrame([{'date':1}]).select(F.explode(F.sequence(F.lit(start),F.lit(end),F.expr(delta))).alias(\"ts_index\")).withColumn(\"position\", F.monotonically_increasing_id())\n",
    "    # if tz is not None:\n",
    "    #     #case kalo di parse_timeindex: weekly granularity bakal nambah index element karena ada Daylight Saving Time. Harus di kurangin \n",
    "    #     #sementara skip dulu\n",
    "    #     pass\n",
    "    #generate row number\n",
    "    w = Window.partitionBy(F.lit(1)).orderBy(\"ts_index\")\n",
    "    date_index = date_index.select(\"ts_index\").distinct().withColumn(\"position\", F.row_number().over(w))\n",
    "    return date_index\n",
    "\n",
    "#parsing generation timeseries function\n",
    "def _parse_generation_timeseries(period_row, df_periods, df_psrtype, df_metric,  per_plant: bool = False, include_eic: bool = False):\n",
    "    #------------------\n",
    "    #get name of psrtype \n",
    "    psrtype = df_psrtype[period_row][0]\n",
    "    if psrtype is None:\n",
    "        psrtype = None\n",
    "    else:\n",
    "        psrtype_name = PSRTYPE_MAPPINGS[psrtype]\n",
    "        name = [psrtype_name]\n",
    "\n",
    "    #check consumption ato aggregated dari nilai inBiddingZone\n",
    "    #kalo inBiddingZone is none, berarti adanya outbidding zone alias metric = consumption atawa consumption element. kalo inBidding zone is not none, berarti metric = aggregated atawa generation element\n",
    "    metric_check = df_metric[period_row][0]\n",
    "    if metric_check is None:\n",
    "        metric = \"Actual Consumption\"\n",
    "    else:\n",
    "        metric = \"Actual Aggregated\"  \n",
    "    name.append(metric)\n",
    "\n",
    "    #skip per plant case\n",
    "    if per_plant:\n",
    "        plantname = \"\"\n",
    "        if include_eic:\n",
    "            pass\n",
    "\n",
    "    #giving the columns set a name (berguna kalo per plantnya kepake aja sih)\n",
    "    if len(name) == 1:\n",
    "        name = name[0]\n",
    "    else: \n",
    "        name = \" - \".join(name)\n",
    "        \n",
    "\n",
    "    #getting the columns for a row of per type generation data and setting up dataframe for the column\n",
    "    #-----------------\n",
    "    #getting quantities\n",
    "    df_periodrow = df_periods[period_row][0]\n",
    "    datas = [(int(point.position), float(point.quantity)) for point in df_periodrow]\n",
    "    datas = spark.createDataFrame(datas, [\"position\", name])\n",
    "\n",
    "    return datas\n",
    "\n",
    "#set the loop count\n",
    "period_row = 2\n",
    "per_plant = False\n",
    "include_eic = False\n",
    "\n",
    "#setting up initial dfs used biar ga berulang2 manggil\n",
    "all_df = _parse_datetimeindex(df_ts, df_nonts, tz=None)\n",
    "all_df.show()\n",
    "\n",
    "periods_col = df_ts.select(F.col(\"Period_point\")).collect()\n",
    "psrtype_col =  df_ts.select(F.col(\"MktPSRType_psrType\")).collect()\n",
    "metric_col = df_ts.select(F.col(\"inBiddingZone_Domain_mRID_text\")).collect()\n",
    "\n",
    "#get range len of periods_col\n",
    "for entry in range(len(periods_col)):\n",
    "    ts_data = _parse_generation_timeseries(entry, periods_col, psrtype_col, metric_col, per_plant=per_plant, include_eic=include_eic)\n",
    "    print(\"ts berhasil diparse\")\n",
    "    all_df = all_df.join(ts_data, [\"position\"], how=\"inner\")\n",
    "\n",
    "all_df = all_df.orderBy(F.asc(\"position\")).drop(\"position\")\n",
    "all_df.show()\n",
    "\n",
    "#skip net and redundant calculation\n",
    "#skip tz convert\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+---------------------------+---------------------------------------------+------------------------------+------------------------------------+------------------------------+------------------------------+----------------------------------------+-----------------------------------------+---------------------------------------------------+-----------------------------------------+---------------------------+-------------------------+-----------------------------------+-------------------------+-------------------------+---------------------------------+--------------------------------+\n",
      "|           ts_index|position|Biomass - Actual Aggregated|Fossil Brown coal/Lignite - Actual Aggregated|Fossil Gas - Actual Aggregated|Fossil Hard coal - Actual Aggregated|Fossil Oil - Actual Aggregated|Geothermal - Actual Aggregated|Hydro Pumped Storage - Actual Aggregated|Hydro Pumped Storage - Actual Consumption|Hydro Run-of-river and poundage - Actual Aggregated|Hydro Water Reservoir - Actual Aggregated|Nuclear - Actual Aggregated|Other - Actual Aggregated|Other renewable - Actual Aggregated|Solar - Actual Aggregated|Waste - Actual Aggregated|Wind Offshore - Actual Aggregated|Wind Onshore - Actual Aggregated|\n",
      "+-------------------+--------+---------------------------+---------------------------------------------+------------------------------+------------------------------------+------------------------------+------------------------------+----------------------------------------+-----------------------------------------+---------------------------------------------------+-----------------------------------------+---------------------------+-------------------------+-----------------------------------+-------------------------+-------------------------+---------------------------------+--------------------------------+\n",
      "|2021-01-01 01:30:00|       7|                     2093.0|                                         20.0|                        1307.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    253.0|                                              486.0|                                     16.0|                     4174.0|                     20.0|                               10.0|                      0.0|                    322.0|                            106.0|                          1376.0|\n",
      "|2021-01-01 01:15:00|       6|                     2096.0|                                         20.0|                        1307.0|                               501.0|                           0.0|                          26.0|                                    72.0|                                      3.0|                                              487.0|                                     10.0|                     4178.0|                     20.0|                               10.0|                      0.0|                    322.0|                             98.0|                          1440.0|\n",
      "|2021-01-01 01:00:00|       5|                     2097.0|                                         20.0|                        1305.0|                               501.0|                           0.0|                          26.0|                                   337.0|                                      0.0|                                              489.0|                                     20.0|                     4169.0|                     20.0|                               10.0|                      0.0|                    322.0|                             87.0|                          1494.0|\n",
      "|2021-01-01 00:00:00|       1|                     2106.0|                                         20.0|                        1405.0|                               677.0|                           0.0|                          26.0|                                     0.0|                                    271.0|                                              506.0|                                     22.0|                     4164.0|                     20.0|                               10.0|                      0.0|                    322.0|                            150.0|                          1738.0|\n",
      "|2021-01-01 00:30:00|       3|                     2104.0|                                         20.0|                        1318.0|                               500.0|                           0.0|                          26.0|                                     0.0|                                     78.0|                                              498.0|                                     13.0|                     4168.0|                     20.0|                               10.0|                      0.0|                    322.0|                            114.0|                          1619.0|\n",
      "|2021-01-01 01:45:00|       8|                     2088.0|                                         20.0|                        1307.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    271.0|                                              484.0|                                     12.0|                     4168.0|                     20.0|                               10.0|                      0.0|                    322.0|                            114.0|                          1287.0|\n",
      "|2021-01-01 00:15:00|       2|                     2105.0|                                         20.0|                        1321.0|                               565.0|                           0.0|                          26.0|                                     0.0|                                     72.0|                                              504.0|                                     14.0|                     4163.0|                     20.0|                               10.0|                      0.0|                    322.0|                            140.0|                          1685.0|\n",
      "|2021-01-01 00:45:00|       4|                     2104.0|                                         20.0|                        1317.0|                               500.0|                           0.0|                          26.0|                                     0.0|                                     86.0|                                              494.0|                                     17.0|                     4169.0|                     20.0|                               10.0|                      0.0|                    322.0|                            104.0|                          1556.0|\n",
      "|2021-01-01 02:00:00|       9|                     2083.0|                                         20.0|                        1321.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    324.0|                                              481.0|                                     13.0|                     4159.0|                     20.0|                               10.0|                      0.0|                    322.0|                            123.0|                          1217.0|\n",
      "|2021-01-01 02:15:00|      10|                     2082.0|                                         20.0|                        1321.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    464.0|                                              481.0|                                      8.0|                     4173.0|                     20.0|                               10.0|                      0.0|                    322.0|                            129.0|                          1141.0|\n",
      "|2021-01-01 02:45:00|      12|                     2073.0|                                         20.0|                        1321.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    704.0|                                              482.0|                                      5.0|                     4170.0|                     20.0|                               10.0|                      0.0|                    322.0|                            133.0|                          1061.0|\n",
      "|2021-01-01 02:30:00|      11|                     2079.0|                                         20.0|                        1321.0|                               501.0|                           0.0|                          26.0|                                     0.0|                                    712.0|                                              482.0|                                      8.0|                     4172.0|                     20.0|                               10.0|                      0.0|                    322.0|                            129.0|                          1076.0|\n",
      "|2021-01-01 03:00:00|      13|                     2079.0|                                         20.0|                        1345.0|                               505.0|                           0.0|                          26.0|                                     0.0|                                    847.0|                                              482.0|                                     11.0|                     4166.0|                     20.0|                               10.0|                      0.0|                    322.0|                            102.0|                          1050.0|\n",
      "|2021-01-01 03:15:00|      14|                     2082.0|                                         20.0|                        1345.0|                               505.0|                           0.0|                          26.0|                                     0.0|                                    720.0|                                              482.0|                                     10.0|                     4166.0|                     20.0|                               10.0|                      0.0|                    322.0|                             86.0|                          1014.0|\n",
      "|2021-01-01 03:30:00|      15|                     2077.0|                                         20.0|                        1350.0|                               505.0|                           0.0|                          26.0|                                     0.0|                                    745.0|                                              481.0|                                      8.0|                     4157.0|                     20.0|                               10.0|                      0.0|                    322.0|                             87.0|                           998.0|\n",
      "|2021-01-01 03:45:00|      16|                     2079.0|                                         20.0|                        1350.0|                               506.0|                           0.0|                          26.0|                                     0.0|                                    786.0|                                              478.0|                                      7.0|                     4158.0|                     20.0|                               10.0|                      0.0|                    322.0|                            106.0|                           971.0|\n",
      "|2021-01-01 04:30:00|      19|                     2096.0|                                         20.0|                        1419.0|                               513.0|                           0.0|                          25.0|                                     0.0|                                    808.0|                                              471.0|                                      8.0|                     4155.0|                     20.0|                               10.0|                      0.0|                    322.0|                            196.0|                           909.0|\n",
      "|2021-01-01 05:15:00|      22|                     2130.0|                                         20.0|                        1445.0|                               517.0|                           0.0|                          25.0|                                     0.0|                                    665.0|                                              470.0|                                     20.0|                     4166.0|                     20.0|                               10.0|                      0.0|                    322.0|                            250.0|                           843.0|\n",
      "|2021-01-01 04:00:00|      17|                     2091.0|                                         20.0|                        1419.0|                               511.0|                           0.0|                          25.0|                                     0.0|                                    763.0|                                              474.0|                                      7.0|                     4167.0|                     20.0|                               10.0|                      0.0|                    322.0|                            139.0|                           956.0|\n",
      "|2021-01-01 04:15:00|      18|                     2098.0|                                         20.0|                        1419.0|                               512.0|                           0.0|                          25.0|                                     0.0|                                    773.0|                                              472.0|                                      8.0|                     4156.0|                     20.0|                               10.0|                      0.0|                    322.0|                            167.0|                           931.0|\n",
      "|2021-01-01 05:00:00|      21|                     2122.0|                                         20.0|                        1445.0|                               516.0|                           0.0|                          25.0|                                     0.0|                                    651.0|                                              470.0|                                      8.0|                     4166.0|                     20.0|                               10.0|                      0.0|                    322.0|                            229.0|                           856.0|\n",
      "|2021-01-01 05:30:00|      23|                     2135.0|                                         20.0|                        1445.0|                               518.0|                           0.0|                          25.0|                                     0.0|                                    663.0|                                              469.0|                                     23.0|                     4167.0|                     20.0|                               10.0|                      0.0|                    322.0|                            240.0|                           833.0|\n",
      "|2021-01-01 04:45:00|      20|                     2093.0|                                         20.0|                        1419.0|                               514.0|                           0.0|                          25.0|                                     0.0|                                    808.0|                                              472.0|                                      8.0|                     4166.0|                     20.0|                               10.0|                      0.0|                    322.0|                            209.0|                           860.0|\n",
      "|2021-01-01 05:45:00|      24|                     2140.0|                                         20.0|                        1445.0|                               528.0|                           0.0|                          25.0|                                     0.0|                                    662.0|                                              468.0|                                     26.0|                     4165.0|                     20.0|                               10.0|                      0.0|                    322.0|                            173.0|                           818.0|\n",
      "+-------------------+--------+---------------------------+---------------------------------------------+------------------------------+------------------------------------+------------------------------+------------------------------+----------------------------------------+-----------------------------------------+---------------------------------------------------+-----------------------------------------+---------------------------+-------------------------+-----------------------------------+-------------------------+-------------------------+---------------------------------+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/03 23:38:16 WARN DefaultCredentialsProvider: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/03 23:38:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Biomass - Actual Aggregated, Fossil Brown coal/Lignite - Actual Aggregated, Fossil Gas - Actual Aggregated, Fossil Hard coal - Actual Aggregated, Fossil Oil - Actual Aggregated, Geothermal - Actual Aggregated, Hydro Pumped Storage - Actual Aggregated, Hydro Pumped Storage - Actual Consumption, Hydro Run-of-river and poundage - Actual Aggregated, Hydro Water Reservoir - Actual Aggregated, Nuclear - Actual Aggregated, Other - Actual Aggregated, Other renewable - Actual Aggregated, Solar - Actual Aggregated, Waste - Actual Aggregated, Wind Offshore - Actual Aggregated, Wind Onshore - Actual Aggregated\n",
      " Schema: _c0, Biomass - Actual Aggregated, Fossil Brown coal/Lignite - Actual Aggregated, Fossil Gas - Actual Aggregated, Fossil Hard coal - Actual Aggregated, Fossil Oil - Actual Aggregated, Geothermal - Actual Aggregated, Hydro Pumped Storage - Actual Aggregated, Hydro Pumped Storage - Actual Consumption, Hydro Run-of-river and poundage - Actual Aggregated, Hydro Water Reservoir - Actual Aggregated, Nuclear - Actual Aggregated, Other - Actual Aggregated, Other renewable - Actual Aggregated, Solar - Actual Aggregated, Waste - Actual Aggregated, Wind Offshore - Actual Aggregated, Wind Onshore - Actual Aggregated\n",
      "Expected: _c0 but found: \n",
      "CSV file: gs://entsoe_analytics_csv_1009/total_generation__DE_TENNET__2021-01-01%2000:00:00+01:00__2021-01-01%2006:00:00+01:00.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#upload to BQ\n",
    "#tulis data ke bigquery via temporary gcs bucket\n",
    "df_spark.write \\\n",
    "  .format(\"bigquery\") \\\n",
    "  .option(\"project\",\"rafzul-analytics-1009\") \\\n",
    "  .option(\"temporaryGcsBucket\",\"entsoe_temp_1009\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .save(\"rafzul-analytics-1009.entsoe_playground.total_generation_staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------- old code ----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create schema to be enforced in subsequent json load operation\n",
    "# with open(\"schema_raw_j\", \"w\") as schrawjson:\n",
    "#     schrawjson.write(df_spark_orig.schema.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"schema_raw2.json\", \"r\") as schrawjson:\n",
    "#     json_schema_data = schrawjson.read()\n",
    "#     json_enforced_schema = StructType.fromJson(json.loads(json_schema_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://entsoe_analytics_1009/entsoe_data_DE_TENNET.json\n"
     ]
    }
   ],
   "source": [
    "# #create dataframe from gcs\n",
    "# path = f\"gs://{gcs_bucket}/{landing_filename}\"\n",
    "# print(path)\n",
    "# df_spark = spark.read.format(\"json\").schema(json_enforced_schema) \\\n",
    "#    .option(\"header\",\"true\") \\\n",
    "#    .option(\"multiLine\",\"true\") \\\n",
    "#    .load(path) \\\n",
    "#    .select(\"GL_MarketDocument.*\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean non timeseries column name. change dot to underscores\n",
    "df_spark = df_spark.toDF(*(c_name.replace(\".\", \"_\") for c_name in df_spark.columns))\n",
    "\n",
    "#clean timeseries column. cast TimeSeries to new scheme where 1.dot in names are replaced with underscores and 2. Strange characters such as '@' or '#' are removed\n",
    "ts_schema = df_spark.select(\"TimeSeries\").dtypes[0][1]\n",
    "replacements = [('\\.', '_'), ('[@#]', '')]\n",
    "for old, new in replacements:\n",
    "    ts_schema = re.sub(old, new, ts_schema)\n",
    "df_spark = df_spark.withColumn(\"TimeSeries\", (F.col(\"TimeSeries\").cast(ts_schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TimeSeries',\n",
       "  'array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,quantity_Measure_Unit_name:string>>')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.select(\"TimeSeries\").dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten column\n",
    "\n",
    "# explode timeseries column into struct\n",
    "df_spark = df_spark.withColumn(\"TimeSeries\", F.explode(\"TimeSeries\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- @xmlns: string (nullable = true)\n",
      " |-- mRID: string (nullable = true)\n",
      " |-- revisionNumber: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- process_processType: string (nullable = true)\n",
      " |-- sender_MarketParticipant_mRID: struct (nullable = true)\n",
      " |    |-- #text: string (nullable = true)\n",
      " |    |-- @codingScheme: string (nullable = true)\n",
      " |-- sender_MarketParticipant_marketRole_type: string (nullable = true)\n",
      " |-- receiver_MarketParticipant_mRID: struct (nullable = true)\n",
      " |    |-- #text: string (nullable = true)\n",
      " |    |-- @codingScheme: string (nullable = true)\n",
      " |-- receiver_MarketParticipant_marketRole_type: string (nullable = true)\n",
      " |-- createdDateTime: string (nullable = true)\n",
      " |-- time_Period_timeInterval: struct (nullable = true)\n",
      " |    |-- end: string (nullable = true)\n",
      " |    |-- start: string (nullable = true)\n",
      " |-- TimeSeries: struct (nullable = true)\n",
      " |    |-- MktPSRType: struct (nullable = true)\n",
      " |    |    |-- psrType: string (nullable = true)\n",
      " |    |-- Period: struct (nullable = true)\n",
      " |    |    |-- Point: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- position: string (nullable = true)\n",
      " |    |    |    |    |-- quantity: string (nullable = true)\n",
      " |    |    |-- resolution: string (nullable = true)\n",
      " |    |    |-- timeInterval: struct (nullable = true)\n",
      " |    |    |    |-- end: string (nullable = true)\n",
      " |    |    |    |-- start: string (nullable = true)\n",
      " |    |-- businessType: string (nullable = true)\n",
      " |    |-- curveType: string (nullable = true)\n",
      " |    |-- inBiddingZone_Domain_mRID: struct (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- codingScheme: string (nullable = true)\n",
      " |    |-- mRID: string (nullable = true)\n",
      " |    |-- objectAggregation: string (nullable = true)\n",
      " |    |-- outBiddingZone_Domain_mRID: struct (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- codingScheme: string (nullable = true)\n",
      " |    |-- quantity_Measure_Unit_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- @xmlns: string (nullable = true)\n",
      " |-- mRID: string (nullable = true)\n",
      " |-- revisionNumber: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- process_processType: string (nullable = true)\n",
      " |-- sender_MarketParticipant_mRID: struct (nullable = true)\n",
      " |    |-- #text: string (nullable = true)\n",
      " |    |-- @codingScheme: string (nullable = true)\n",
      " |-- sender_MarketParticipant_marketRole_type: string (nullable = true)\n",
      " |-- receiver_MarketParticipant_mRID: struct (nullable = true)\n",
      " |    |-- #text: string (nullable = true)\n",
      " |    |-- @codingScheme: string (nullable = true)\n",
      " |-- receiver_MarketParticipant_marketRole_type: string (nullable = true)\n",
      " |-- createdDateTime: string (nullable = true)\n",
      " |-- time_Period_timeInterval: struct (nullable = true)\n",
      " |    |-- end: string (nullable = true)\n",
      " |    |-- start: string (nullable = true)\n",
      " |-- TimeSeries_MktPSRType: struct (nullable = true)\n",
      " |    |-- psrType: string (nullable = true)\n",
      " |-- TimeSeries_Period: struct (nullable = true)\n",
      " |    |-- Point: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- position: string (nullable = true)\n",
      " |    |    |    |-- quantity: string (nullable = true)\n",
      " |    |-- resolution: string (nullable = true)\n",
      " |    |-- timeInterval: struct (nullable = true)\n",
      " |    |    |-- end: string (nullable = true)\n",
      " |    |    |-- start: string (nullable = true)\n",
      " |-- TimeSeries_businessType: string (nullable = true)\n",
      " |-- TimeSeries_curveType: string (nullable = true)\n",
      " |-- TimeSeries_inBiddingZone_Domain_mRID: struct (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- codingScheme: string (nullable = true)\n",
      " |-- TimeSeries_mRID: string (nullable = true)\n",
      " |-- TimeSeries_objectAggregation: string (nullable = true)\n",
      " |-- TimeSeries_outBiddingZone_Domain_mRID: struct (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- codingScheme: string (nullable = true)\n",
      " |-- TimeSeries_quantity_Measure_Unit_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# flatten TimeSeries if there is TimeSeries, flatten AttributeInstanceComponent if there is AttributeInstanceComponent\n",
    "def unpack_df(nested_df):\n",
    "    component_columns = [\"TimeSeries\", \"AttributeInstanceComponent\"]\n",
    "    general_cols = [c for c in nested_df.columns if c not in component_columns]\n",
    "    if \"TimeSeries\" in nested_df.columns:\n",
    "        data_cols_name = \"TimeSeries\"\n",
    "        data_cols = [c for c in nested_df.select(\"TimeSeries.*\").columns]\n",
    "    else:\n",
    "        pass\n",
    "    unpacked_df = nested_df.select(general_cols \\\n",
    "                                   + [F.col(data_cols_name+\".\"+c).alias(data_cols_name+\"_\"+c)\\\n",
    "                                      for c in data_cols])\n",
    "    return unpacked_df\n",
    "    \n",
    "\n",
    "df_spark = unpack_df(df_spark)\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/09 08:26:31 WARN DefaultCredentialsProvider: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/10 04:08:50 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 70779659 ms exceeds timeout 120000 ms\n",
      "23/01/10 04:08:50 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "#tulis data ke bigquery via temporary gcs bucket\n",
    "all_df.write \\\n",
    "  .format(\"bigquery\") \\\n",
    "  .option(\"project\",\"rafzul-analytics-1009\") \\\n",
    "  .option(\"temporaryGcsBucket\",\"entsoe_temp_1009\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .save(\"rafzul-analytics-1009.entsoe_playground.total_generation_staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if df_spark2.select(\"TimeSeries\"):\n",
    "#     # rename all column (specifically replace dot with underscore) on every struct nested in TimeSeries array column. use transform\n",
    "#     df_spark3 = df_spark3.withColumn(\"TimeSeries\", F.transform \\\n",
    "#     (\"TimeSeries\", lambda el,ind: \\\n",
    "#     F.struct \\\n",
    "#     (\"abc\" for c_name in el.columns)))\n",
    "    \n",
    "# # # #get list of names of all columns in every struct inside TimeSeries array column\n",
    "# # a = [x for x in df_spark2.select((\"TimeSeries\"))]\n",
    "# # print(a)\n",
    "\n",
    "# df_spark3.select(\"TimeSeries\").show(10, truncate=False)\n",
    "# a = F.struct(F.col(\"TimeSeries\").getItem(c_name).alias(c_name.replace(\".\", \"_\")) for i, c_name in enumerate(df_spark2.schema[\"TimeSeries\"].dataType.elementType.fieldNames()))\n",
    "# # print(a\n",
    "\n",
    "\n",
    "# F.struct(F.col(\"TimeSeries\") for c_name in df_spark2.schema[x].dataType.names\n",
    "\n",
    "\n",
    "# df_spark2.show()\n",
    "# df_spark2.printSchema()\n",
    "\n",
    "# # #get list of names of all columns in every struct inside TimeSeries array column\n",
    "# a = [(c_name,i) for (c_name,i) in enumerate(df_spark2.schema[\"TimeSeries\"].dataType.elementType.fieldNames())]\n",
    "# print(a)\n",
    "\n",
    "\n",
    "# df_spark2 = df_spark2.withColumn(\"TimeSeries\", F.transform(\"TimeSeries\", lambda x: F.struct(*[F.col(\"TimeSeries.\" + c_name.replace(\".\", \"_\")).alias(c_name) for c_name in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for non timeseries column\n",
    "# df_spark2 = df_spark2.toDF(*(c_name.replace(\".\", \"_\") for c_name in df_spark2.columns))\n",
    "# b = df_spark2.select(F.col(\"TimeSeries\"))\n",
    "# #for timeseries one\n",
    "# a = F.struct(F.col(\"TimeSeries\").getItem(c_name).alias(c_name.replace(\".\", \"_\")) for i, c_name in enumerate(df_spark2.schema[\"TimeSeries\"].dataType.elementType.fieldNames()))\n",
    "# print(a)\n",
    "# if df_spark2.select(\"TimeSeries\"):\n",
    "#     # rename all column (specifically replace dot with underscore) on every struct nested in TimeSeries array column. use transform, use Timeseries schema and its datatype.name o\n",
    "#     df_spark2 = df_spark2.withColumn(\"TimeSeries\", F.transform(\"TimeSeries\", lambda x: (a)))\n",
    "    \n",
    "# # #get list of names of all columns in every struct inside TimeSeries array column\n",
    "# # a = [c_name for c_name in enumerate(df_spark2.schema[\"TimeSeries\"].dataType.elementType.fieldNames())]\n",
    "\n",
    "\n",
    "# df_spark3.show()\n",
    "# df_spark3.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "# # df_spark2 = df_spark2.withColumn(\"TimeSeries\", F.transform(\"TimeSeries\", lambda x: F.struct(*[F.col(\"TimeSeries.\" + c_name.replace(\".\", \"_\")).alias(c_name) for c_name in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cast schema with the dot replaced with underscore, programatically\n",
    "\n",
    "\n",
    "# ---- solution for  column names beside TimeSeries:\n",
    "# changed_column_general = [(column_name, column_name.replace(\".\", \"_\")) for column_name in df_schema.fieldNames() if \".\" in x]\n",
    "# for column_name, changed_column_name in changed_column_general:\n",
    "#     df_schema = df_spark2.select([F.col(c).alias(mappingcolumn_name, changed_column_name)\n",
    "# # UPDATE: there is even better solution\n",
    "\n",
    "# #changed non timeseries column\n",
    "# df_spark2 = df_spark2.toDF(*(c.replace(\".\", \"_\") for c in df_spark2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not RDD",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rafzul/projects/entsoe-pipelines/prototype.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafzul/projects/entsoe-pipelines/prototype.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mexample_destination.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw+\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m output_file:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rafzul/projects/entsoe-pipelines/prototype.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     output_file\u001b[39m.\u001b[39;49mwrite(df_spark2\u001b[39m.\u001b[39;49mtoJSON())\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not RDD"
     ]
    }
   ],
   "source": [
    "with open(\"example_destination.json\", \"w+\") as output_file:\n",
    "    output_file.write(df_spark2.toJSON())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #inferring schema and get the data type of each column and turn it into spark dataframe\n",
    "# datatype_infer = pd.DataFrame.from_dict(xml_file_dict[0], orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #flatten nested df at every layer\n",
    "# from pyspark.sql.types import *\n",
    "# from pyspark.sql.import functions as f\n",
    "\n",
    "# def flatten_structs(nested_df):\n",
    "#     stack = [(), nested_df]\n",
    "#     columns = []\n",
    "    \n",
    "#     while len(stack) > 0:\n",
    "#         parents\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_schema = df_spark.dtypes\n",
    "\n",
    "# firstrow_orig = df_spark.collect()[0]\n",
    "# new_header = [f\"{x} - {firstrow_orig.__getitem__(x)}\" for x in firstrow_orig.__fields__]\n",
    "\n",
    "# df_spark = df_spark.where(F.col(\"_c0\").isNotNull())\n",
    "# df_spark.show()\n",
    "\n",
    "# # #drop header and first column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original code to read json file \n",
    "\n",
    "try: \n",
    "   df_spark = spark.read.format(\"json\") \\\n",
    "      .option(\"inferSchema\",\"true\") \\\n",
    "      .option(\"multiLine\",\"true\") \\\n",
    "      .load(path) \\\n",
    "      .select(\"GL_MarketDocument.*\")\n",
    "except Exception as e:\n",
    "   pass\n",
    "   # df_spark = spark.read.format(\"csv\") \\\n",
    "   #    .option(\"inferSchema\",\"true\") \\\n",
    "   #    .option(\"header\",\"true\") \\\n",
    "   #    .load(path)\n",
    "   # schema_version = source_schema_version + 0.1\n",
    "   # new_source_schema = { \"version\": float(schema_version),\"schema\": df_spark.schema.jsonValue()}\n",
    "   # new_source_schema_json = json.dumps(new_source_schema)\n",
    "   # new_source_schema_filename = f\"schema_source/{label_data}__schema__{schema_version}.json\"\n",
    "   # upload_blob_to_gcs(bucket_name=gcs_bucket, contents=new_source_schema_json, destination_blob_name=new_source_schema_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing generation timeseries\n",
    "\n",
    "positions = []\n",
    "quantities = []\n",
    "\n",
    "example_row = []\n",
    "#contoh 1 row, equivalent of parse_generation_timeseries function\n",
    "#bagian ini dirubah ke parse_generation alias semua yg row di collect dijadiin looping buat collect() [x][0] for x in range(len())\n",
    "df_periods = df_ts.select(F.col(\"Period_point\")).collect()\n",
    "df_periods_1 = df_periods[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting quantities\n",
    "# quantities = [float(point.quantity) for point in df_periodrow]\n",
    "quantities = []\n",
    "df_periodrow = df_periods[period_row][0]\n",
    "for point in df_periodrow:\n",
    "    quantity = point.quantity\n",
    "    if quantity is None:\n",
    "        raise LookupError(\n",
    "        f'No quantity found in this point, it should have one: {point}')\n",
    "    quantities.append(float(point.quantity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

[2023-01-30T11:03:53.283+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: entsoe-energydata.stage_total_generation scheduled__2021-01-01T05:00:00+00:00 [queued]>
[2023-01-30T11:03:53.297+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: entsoe-energydata.stage_total_generation scheduled__2021-01-01T05:00:00+00:00 [queued]>
[2023-01-30T11:03:53.297+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2023-01-30T11:03:53.297+0000] {taskinstance.py:1284} INFO - Starting attempt 2 of 4
[2023-01-30T11:03:53.298+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2023-01-30T11:03:53.314+0000] {taskinstance.py:1304} INFO - Executing <Task(SparkSubmitOperator): stage_total_generation> on 2021-01-01 05:00:00+00:00
[2023-01-30T11:03:53.325+0000] {standard_task_runner.py:55} INFO - Started process 1735 to run task
[2023-01-30T11:03:53.331+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'entsoe-energydata', 'stage_total_generation', 'scheduled__2021-01-01T05:00:00+00:00', '--job-id', '550', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_energydata_dag.py', '--cfg-path', '/tmp/tmpzojcgcbi']
[2023-01-30T11:03:53.335+0000] {standard_task_runner.py:83} INFO - Job 550: Subtask stage_total_generation
[2023-01-30T11:03:53.428+0000] {task_command.py:389} INFO - Running <TaskInstance: entsoe-energydata.stage_total_generation scheduled__2021-01-01T05:00:00+00:00 [running]> on host 5b6f5d29e531
[2023-01-30T11:03:53.532+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=rafzul
AIRFLOW_CTX_DAG_ID=entsoe-energydata
AIRFLOW_CTX_TASK_ID=stage_total_generation
AIRFLOW_CTX_EXECUTION_DATE=2021-01-01T05:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-01-01T05:00:00+00:00
[2023-01-30T11:03:53.546+0000] {base.py:73} INFO - Using connection ID 'spark_local' for task execution.
[2023-01-30T11:03:53.548+0000] {spark_submit.py:344} INFO - Spark-Submit cmd: spark-submit --master local --name arrow-spark /opt/***/plugins/scripts/transform_raw_staging.py total_generation 202101010500 202101010600 DE_TENNET
[2023-01-30T11:04:06.884+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:06 INFO SparkContext: Running Spark version 3.3.1
[2023-01-30T11:04:07.296+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-01-30T11:04:07.701+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:07 INFO ResourceUtils: ==============================================================
[2023-01-30T11:04:07.702+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:07 INFO ResourceUtils: No custom resources configured for spark.driver.
[2023-01-30T11:04:07.703+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:07 INFO ResourceUtils: ==============================================================
[2023-01-30T11:04:07.705+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:07 INFO SparkContext: Submitted application: gcp_playground
[2023-01-30T11:04:07.823+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2023-01-30T11:04:07.845+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:07 INFO ResourceProfile: Limiting resource is cpu
[2023-01-30T11:04:07.851+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:07 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2023-01-30T11:04:08.250+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:08 INFO SecurityManager: Changing view acls to: ***
[2023-01-30T11:04:08.251+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:08 INFO SecurityManager: Changing modify acls to: ***
[2023-01-30T11:04:08.253+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:08 INFO SecurityManager: Changing view acls groups to:
[2023-01-30T11:04:08.254+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:08 INFO SecurityManager: Changing modify acls groups to:
[2023-01-30T11:04:08.258+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(***); groups with view permissions: Set(); users  with modify permissions: Set(***); groups with modify permissions: Set()
[2023-01-30T11:04:09.471+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:09 INFO Utils: Successfully started service 'sparkDriver' on port 41311.
[2023-01-30T11:04:09.720+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:09 INFO SparkEnv: Registering MapOutputTracker
[2023-01-30T11:04:09.984+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:09 INFO SparkEnv: Registering BlockManagerMaster
[2023-01-30T11:04:10.165+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2023-01-30T11:04:10.169+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2023-01-30T11:04:10.203+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2023-01-30T11:04:10.355+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-74e4b0d0-c311-4090-beb0-da3b6856ebb2
[2023-01-30T11:04:10.540+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:10 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2023-01-30T11:04:10.756+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:10 INFO SparkEnv: Registering OutputCommitCoordinator
[2023-01-30T11:04:11.888+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2023-01-30T11:04:12.150+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:12 INFO SparkContext: Added JAR /opt/spark/jars/gcs-connector-hadoop3-latest.jar at spark://5b6f5d29e531:41311/jars/gcs-connector-hadoop3-latest.jar with timestamp 1675076646840
[2023-01-30T11:04:12.153+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:12 INFO SparkContext: Added JAR /opt/spark/jars/spark-bigquery-with-dependencies_2.13-0.27.1.jar at spark://5b6f5d29e531:41311/jars/spark-bigquery-with-dependencies_2.13-0.27.1.jar with timestamp 1675076646840
[2023-01-30T11:04:12.566+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:12 INFO Executor: Starting executor ID driver on host 5b6f5d29e531
[2023-01-30T11:04:12.609+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:12 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2023-01-30T11:04:12.691+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:12 INFO Executor: Fetching spark://5b6f5d29e531:41311/jars/gcs-connector-hadoop3-latest.jar with timestamp 1675076646840
[2023-01-30T11:04:13.259+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:13 INFO TransportClientFactory: Successfully created connection to 5b6f5d29e531/172.21.0.7:41311 after 342 ms (0 ms spent in bootstraps)
[2023-01-30T11:04:13.355+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:13 INFO Utils: Fetching spark://5b6f5d29e531:41311/jars/gcs-connector-hadoop3-latest.jar to /tmp/spark-d717c717-a6d1-4e87-a2a3-8baaee4bfcfe/userFiles-56ba8e69-9238-424b-8df7-595a254446c2/fetchFileTemp13379970064237971749.tmp
[2023-01-30T11:04:14.916+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:14 INFO Executor: Adding file:/tmp/spark-d717c717-a6d1-4e87-a2a3-8baaee4bfcfe/userFiles-56ba8e69-9238-424b-8df7-595a254446c2/gcs-connector-hadoop3-latest.jar to class loader
[2023-01-30T11:04:14.917+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:14 INFO Executor: Fetching spark://5b6f5d29e531:41311/jars/spark-bigquery-with-dependencies_2.13-0.27.1.jar with timestamp 1675076646840
[2023-01-30T11:04:14.933+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:14 INFO Utils: Fetching spark://5b6f5d29e531:41311/jars/spark-bigquery-with-dependencies_2.13-0.27.1.jar to /tmp/spark-d717c717-a6d1-4e87-a2a3-8baaee4bfcfe/userFiles-56ba8e69-9238-424b-8df7-595a254446c2/fetchFileTemp3256830207960450632.tmp
[2023-01-30T11:04:15.767+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:15 INFO Executor: Adding file:/tmp/spark-d717c717-a6d1-4e87-a2a3-8baaee4bfcfe/userFiles-56ba8e69-9238-424b-8df7-595a254446c2/spark-bigquery-with-dependencies_2.13-0.27.1.jar to class loader
[2023-01-30T11:04:15.857+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35827.
[2023-01-30T11:04:15.859+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:15 INFO NettyBlockTransferService: Server created on 5b6f5d29e531:35827
[2023-01-30T11:04:15.859+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2023-01-30T11:04:15.912+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:04:15.967+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:15 INFO BlockManagerMasterEndpoint: Registering block manager 5b6f5d29e531:35827 with 434.4 MiB RAM, BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:04:15.984+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:04:15.988+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:04:25.311+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2023-01-30T11:04:25.573+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:25 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2023-01-30T11:04:46.705+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:46 INFO InMemoryFileIndex: It took 1106 ms to list leaf files for 1 paths.
[2023-01-30T11:04:48.819+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 201.9 KiB, free 434.2 MiB)
[2023-01-30T11:04:49.346+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 434.2 MiB)
[2023-01-30T11:04:49.360+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 5b6f5d29e531:35827 (size: 34.6 KiB, free: 434.4 MiB)
[2023-01-30T11:04:49.373+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:49 INFO SparkContext: Created broadcast 0 from load at NativeMethodAccessorImpl.java:0
[2023-01-30T11:04:53.408+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:53 INFO FileInputFormat: Total input files to process : 1
[2023-01-30T11:04:53.852+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:53 INFO FileInputFormat: Total input files to process : 1
[2023-01-30T11:04:54.169+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0
[2023-01-30T11:04:54.311+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2023-01-30T11:04:54.319+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)
[2023-01-30T11:04:54.320+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:04:54.343+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:04:54.384+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at load at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-01-30T11:04:54.797+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.6 KiB, free 434.2 MiB)
[2023-01-30T11:04:54.815+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 434.2 MiB)
[2023-01-30T11:04:54.818+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 5b6f5d29e531:35827 (size: 4.6 KiB, free: 434.4 MiB)
[2023-01-30T11:04:54.823+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:04:54.939+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:04:54.955+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2023-01-30T11:04:55.483+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7578 bytes) taskResourceAssignments Map()
[2023-01-30T11:04:55.590+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2023-01-30T11:04:56.491+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:56 INFO BinaryFileRDD: Input split: Paths:/total_generation__DE_TENNET__202101010500__202101010600.json:0+9367
[2023-01-30T11:04:57.975+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 3437 bytes result sent to driver
[2023-01-30T11:04:58.055+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2699 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:04:58.092+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2023-01-30T11:04:58.194+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:58 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 3.682 s
[2023-01-30T11:04:58.259+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:58 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:04:58.267+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2023-01-30T11:04:58.284+0000] {spark_submit.py:495} INFO - 23/01/30 11:04:58 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 4.112659 s
[2023-01-30T11:05:07.769+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 5b6f5d29e531:35827 in memory (size: 34.6 KiB, free: 434.4 MiB)
[2023-01-30T11:05:08.011+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 5b6f5d29e531:35827 in memory (size: 4.6 KiB, free: 434.4 MiB)
[2023-01-30T11:05:32.875+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:32 INFO FileSourceStrategy: Pushed Filters:
[2023-01-30T11:05:32.881+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:32 INFO FileSourceStrategy: Post-Scan Filters:
[2023-01-30T11:05:32.888+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:32 INFO FileSourceStrategy: Output Data Schema: struct<GL_MarketDocument: struct<@xmlns: string, TimeSeries: array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,quantity_Measure_Unit.name:string>>, createdDateTime: string, mRID: string, process.processType: string ... 10 more fields>>
[2023-01-30T11:05:35.135+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO CodeGenerator: Code generated in 957.371341 ms
[2023-01-30T11:05:35.175+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 201.3 KiB, free 434.2 MiB)
[2023-01-30T11:05:35.249+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 434.2 MiB)
[2023-01-30T11:05:35.255+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (size: 34.5 KiB, free: 434.4 MiB)
[2023-01-30T11:05:35.263+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO SparkContext: Created broadcast 2 from collect at /opt/***/plugins/helpers/parsers.py:42
[2023-01-30T11:05:35.306+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4203671 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-30T11:05:35.808+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO SparkContext: Starting job: collect at /opt/***/plugins/helpers/parsers.py:42
[2023-01-30T11:05:35.813+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO DAGScheduler: Got job 1 (collect at /opt/***/plugins/helpers/parsers.py:42) with 1 output partitions
[2023-01-30T11:05:35.815+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO DAGScheduler: Final stage: ResultStage 1 (collect at /opt/***/plugins/helpers/parsers.py:42)
[2023-01-30T11:05:35.816+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:05:35.817+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:05:35.839+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at collect at /opt/***/plugins/helpers/parsers.py:42), which has no missing parents
[2023-01-30T11:05:35.897+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.9 KiB, free 434.2 MiB)
[2023-01-30T11:05:35.925+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 434.1 MiB)
[2023-01-30T11:05:35.938+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 5b6f5d29e531:35827 (size: 7.8 KiB, free: 434.4 MiB)
[2023-01-30T11:05:35.941+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:05:35.945+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at collect at /opt/***/plugins/helpers/parsers.py:42) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:05:35.956+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2023-01-30T11:05:35.986+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
[2023-01-30T11:05:36.003+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2023-01-30T11:05:36.511+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:36 INFO FileScanRDD: Reading File path: gs://entsoe_analytics_1009/total_generation__DE_TENNET__202101010500__202101010600.json, range: 0-9367, partition values: [empty row]
[2023-01-30T11:05:37.718+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:37 INFO CodeGenerator: Code generated in 809.4014 ms
[2023-01-30T11:05:38.939+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1628 bytes result sent to driver
[2023-01-30T11:05:38.974+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3007 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:05:38.982+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:38 INFO DAGScheduler: ResultStage 1 (collect at /opt/***/plugins/helpers/parsers.py:42) finished in 3.109 s
[2023-01-30T11:05:38.992+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:38 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:05:38.996+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2023-01-30T11:05:39.006+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2023-01-30T11:05:39.011+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO DAGScheduler: Job 1 finished: collect at /opt/***/plugins/helpers/parsers.py:42, took 3.198998 s
[2023-01-30T11:05:39.542+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO FileSourceStrategy: Pushed Filters:
[2023-01-30T11:05:39.543+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO FileSourceStrategy: Post-Scan Filters:
[2023-01-30T11:05:39.545+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO FileSourceStrategy: Output Data Schema: struct<GL_MarketDocument: struct<@xmlns: string, TimeSeries: array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,quantity_Measure_Unit.name:string>>, createdDateTime: string, mRID: string, process.processType: string ... 10 more fields>>
[2023-01-30T11:05:39.641+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO CodeGenerator: Code generated in 69.882458 ms
[2023-01-30T11:05:39.656+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 201.3 KiB, free 433.9 MiB)
[2023-01-30T11:05:39.704+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.9 MiB)
[2023-01-30T11:05:39.707+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 5b6f5d29e531:35827 (size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:05:39.711+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO SparkContext: Created broadcast 4 from collect at /opt/***/plugins/helpers/parsers.py:45
[2023-01-30T11:05:39.715+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4203671 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-30T11:05:39.967+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO SparkContext: Starting job: collect at /opt/***/plugins/helpers/parsers.py:45
[2023-01-30T11:05:39.968+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO DAGScheduler: Got job 2 (collect at /opt/***/plugins/helpers/parsers.py:45) with 1 output partitions
[2023-01-30T11:05:39.968+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO DAGScheduler: Final stage: ResultStage 2 (collect at /opt/***/plugins/helpers/parsers.py:45)
[2023-01-30T11:05:39.969+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:05:39.969+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:05:39.975+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at /opt/***/plugins/helpers/parsers.py:45), which has no missing parents
[2023-01-30T11:05:40.021+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.9 KiB, free 433.9 MiB)
[2023-01-30T11:05:40.080+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 433.9 MiB)
[2023-01-30T11:05:40.087+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 5b6f5d29e531:35827 (size: 7.8 KiB, free: 434.3 MiB)
[2023-01-30T11:05:40.095+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:40 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:05:40.108+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at /opt/***/plugins/helpers/parsers.py:45) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:05:40.113+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2023-01-30T11:05:40.126+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
[2023-01-30T11:05:40.131+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:40 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
[2023-01-30T11:05:40.251+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:40 INFO FileScanRDD: Reading File path: gs://entsoe_analytics_1009/total_generation__DE_TENNET__202101010500__202101010600.json, range: 0-9367, partition values: [empty row]
[2023-01-30T11:05:40.978+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1585 bytes result sent to driver
[2023-01-30T11:05:41.018+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 888 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:05:41.019+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:41 INFO DAGScheduler: ResultStage 2 (collect at /opt/***/plugins/helpers/parsers.py:45) finished in 1.032 s
[2023-01-30T11:05:41.019+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:41 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:05:41.023+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2023-01-30T11:05:41.028+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2023-01-30T11:05:41.029+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:41 INFO DAGScheduler: Job 2 finished: collect at /opt/***/plugins/helpers/parsers.py:45, took 1.061933 s
[2023-01-30T11:05:42.216+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:42 INFO FileSourceStrategy: Pushed Filters:
[2023-01-30T11:05:42.230+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:42 INFO FileSourceStrategy: Post-Scan Filters: (size(cast(GL_MarketDocument#0 as struct<xmlns:string,TimeSeries:array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,quantity_Measure_Unit_name:string>>,createdDateTime:string,mRID:string,process_processType:string,receiver_MarketParticipant_mRID:struct<text:string,codingScheme:string>,receiver_MarketParticipant_marketRole_type:string,revisionNumber:string,sender_MarketParticipant_mRID:struct<text:string,codingScheme:string>,sender_MarketParticipant_marketRole_type:string,time_Period_timeInterval:struct<end:string,start:string>,type:string>).TimeSeries.Period.resolution, true) > 0),isnotnull(cast(GL_MarketDocument#0 as struct<xmlns:string,TimeSeries:array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,quantity_Measure_Unit_name:string>>,createdDateTime:string,mRID:string,process_processType:string,receiver_MarketParticipant_mRID:struct<text:string,codingScheme:string>,receiver_MarketParticipant_marketRole_type:string,revisionNumber:string,sender_MarketParticipant_mRID:struct<text:string,codingScheme:string>,sender_MarketParticipant_marketRole_type:string,time_Period_timeInterval:struct<end:string,start:string>,type:string>).TimeSeries.Period.resolution)
[2023-01-30T11:05:42.247+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:42 INFO FileSourceStrategy: Output Data Schema: struct<GL_MarketDocument: struct<@xmlns: string, TimeSeries: array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,quantity_Measure_Unit.name:string>>, createdDateTime: string, mRID: string, process.processType: string ... 10 more fields>>
[2023-01-30T11:05:43.401+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:43 INFO CodeGenerator: Code generated in 936.638855 ms
[2023-01-30T11:05:43.492+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:43 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 201.3 KiB, free 433.7 MiB)
[2023-01-30T11:05:43.719+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:43 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.7 MiB)
[2023-01-30T11:05:43.722+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 5b6f5d29e531:35827 (size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:05:43.725+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:43 INFO SparkContext: Created broadcast 6 from collect at /opt/***/plugins/helpers/parsers.py:57
[2023-01-30T11:05:43.737+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4203671 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-30T11:05:44.147+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 5b6f5d29e531:35827 in memory (size: 7.8 KiB, free: 434.3 MiB)
[2023-01-30T11:05:44.293+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 5b6f5d29e531:35827 in memory (size: 7.8 KiB, free: 434.3 MiB)
[2023-01-30T11:05:44.299+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO SparkContext: Starting job: collect at /opt/***/plugins/helpers/parsers.py:57
[2023-01-30T11:05:44.302+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO DAGScheduler: Got job 3 (collect at /opt/***/plugins/helpers/parsers.py:57) with 1 output partitions
[2023-01-30T11:05:44.302+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO DAGScheduler: Final stage: ResultStage 3 (collect at /opt/***/plugins/helpers/parsers.py:57)
[2023-01-30T11:05:44.303+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:05:44.304+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:05:44.318+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[14] at collect at /opt/***/plugins/helpers/parsers.py:57), which has no missing parents
[2023-01-30T11:05:44.334+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 36.5 KiB, free 433.7 MiB)
[2023-01-30T11:05:44.341+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.7 MiB)
[2023-01-30T11:05:44.345+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 5b6f5d29e531:35827 (size: 12.7 KiB, free: 434.3 MiB)
[2023-01-30T11:05:44.349+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:05:44.357+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at collect at /opt/***/plugins/helpers/parsers.py:57) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:05:44.360+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2023-01-30T11:05:44.365+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
[2023-01-30T11:05:44.366+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
[2023-01-30T11:05:44.459+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO FileScanRDD: Reading File path: gs://entsoe_analytics_1009/total_generation__DE_TENNET__202101010500__202101010600.json, range: 0-9367, partition values: [empty row]
[2023-01-30T11:05:44.788+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1712 bytes result sent to driver
[2023-01-30T11:05:44.817+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 454 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:05:44.824+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO DAGScheduler: ResultStage 3 (collect at /opt/***/plugins/helpers/parsers.py:57) finished in 0.506 s
[2023-01-30T11:05:44.827+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:05:44.837+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2023-01-30T11:05:44.848+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2023-01-30T11:05:44.849+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:44 INFO DAGScheduler: Job 3 finished: collect at /opt/***/plugins/helpers/parsers.py:57, took 0.552530 s
[2023-01-30T11:05:45.079+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO FileSourceStrategy: Pushed Filters:
[2023-01-30T11:05:45.080+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO FileSourceStrategy: Post-Scan Filters:
[2023-01-30T11:05:45.081+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO FileSourceStrategy: Output Data Schema: struct<GL_MarketDocument: struct<@xmlns: string, TimeSeries: array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,quantity_Measure_Unit.name:string>>, createdDateTime: string, mRID: string, process.processType: string ... 10 more fields>>
[2023-01-30T11:05:45.222+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO CodeGenerator: Code generated in 97.789959 ms
[2023-01-30T11:05:45.265+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 201.3 KiB, free 433.5 MiB)
[2023-01-30T11:05:45.346+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.4 MiB)
[2023-01-30T11:05:45.349+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 5b6f5d29e531:35827 (size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:05:45.354+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO SparkContext: Created broadcast 8 from collect at /opt/***/plugins/helpers/parsers.py:63
[2023-01-30T11:05:45.368+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4203671 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-30T11:05:45.612+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO SparkContext: Starting job: collect at /opt/***/plugins/helpers/parsers.py:63
[2023-01-30T11:05:45.617+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO DAGScheduler: Got job 4 (collect at /opt/***/plugins/helpers/parsers.py:63) with 1 output partitions
[2023-01-30T11:05:45.618+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO DAGScheduler: Final stage: ResultStage 4 (collect at /opt/***/plugins/helpers/parsers.py:63)
[2023-01-30T11:05:45.618+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:05:45.619+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:05:45.629+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at /opt/***/plugins/helpers/parsers.py:63), which has no missing parents
[2023-01-30T11:05:45.646+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.7 KiB, free 433.4 MiB)
[2023-01-30T11:05:45.656+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 433.4 MiB)
[2023-01-30T11:05:45.660+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 5b6f5d29e531:35827 (size: 7.7 KiB, free: 434.2 MiB)
[2023-01-30T11:05:45.666+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:05:45.676+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at /opt/***/plugins/helpers/parsers.py:63) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:05:45.677+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2023-01-30T11:05:45.687+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
[2023-01-30T11:05:45.715+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
[2023-01-30T11:05:45.787+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:45 INFO FileScanRDD: Reading File path: gs://entsoe_analytics_1009/total_generation__DE_TENNET__202101010500__202101010600.json, range: 0-9367, partition values: [empty row]
[2023-01-30T11:05:46.186+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:46 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1586 bytes result sent to driver
[2023-01-30T11:05:46.204+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:46 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 509 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:05:46.206+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:46 INFO DAGScheduler: ResultStage 4 (collect at /opt/***/plugins/helpers/parsers.py:63) finished in 0.567 s
[2023-01-30T11:05:46.208+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:46 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:05:46.210+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:46 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2023-01-30T11:05:46.213+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2023-01-30T11:05:46.218+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:46 INFO DAGScheduler: Job 4 finished: collect at /opt/***/plugins/helpers/parsers.py:63, took 0.602446 s
[2023-01-30T11:05:48.538+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:48 INFO FileSourceStrategy: Pushed Filters:
[2023-01-30T11:05:48.541+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:48 INFO FileSourceStrategy: Post-Scan Filters: (size(cast(GL_MarketDocument#0 as struct<xmlns:string,TimeSeries:array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,quantity_Measure_Unit_name:string>>,createdDateTime:string,mRID:string,process_processType:string,receiver_MarketParticipant_mRID:struct<text:string,codingScheme:string>,receiver_MarketParticipant_marketRole_type:string,revisionNumber:string,sender_MarketParticipant_mRID:struct<text:string,codingScheme:string>,sender_MarketParticipant_marketRole_type:string,time_Period_timeInterval:struct<end:string,start:string>,type:string>).TimeSeries.Period.Point, true) > 0),isnotnull(cast(GL_MarketDocument#0 as struct<xmlns:string,TimeSeries:array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,quantity_Measure_Unit_name:string>>,createdDateTime:string,mRID:string,process_processType:string,receiver_MarketParticipant_mRID:struct<text:string,codingScheme:string>,receiver_MarketParticipant_marketRole_type:string,revisionNumber:string,sender_MarketParticipant_mRID:struct<text:string,codingScheme:string>,sender_MarketParticipant_marketRole_type:string,time_Period_timeInterval:struct<end:string,start:string>,type:string>).TimeSeries.Period.Point)
[2023-01-30T11:05:48.541+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:48 INFO FileSourceStrategy: Output Data Schema: struct<GL_MarketDocument: struct<@xmlns: string, TimeSeries: array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,quantity_Measure_Unit.name:string>>, createdDateTime: string, mRID: string, process.processType: string ... 10 more fields>>
[2023-01-30T11:05:49.731+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:49 INFO CodeGenerator: Code generated in 957.492194 ms
[2023-01-30T11:05:49.942+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:49 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 201.3 KiB, free 433.2 MiB)
[2023-01-30T11:05:50.011+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:49 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.2 MiB)
[2023-01-30T11:05:50.044+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 5b6f5d29e531:35827 (size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:05:50.044+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO SparkContext: Created broadcast 10 from collect at /opt/***/plugins/scripts/transform_raw_staging.py:190
[2023-01-30T11:05:50.045+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4203671 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-30T11:05:50.155+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO SparkContext: Starting job: collect at /opt/***/plugins/scripts/transform_raw_staging.py:190
[2023-01-30T11:05:50.158+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO DAGScheduler: Got job 5 (collect at /opt/***/plugins/scripts/transform_raw_staging.py:190) with 1 output partitions
[2023-01-30T11:05:50.159+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO DAGScheduler: Final stage: ResultStage 5 (collect at /opt/***/plugins/scripts/transform_raw_staging.py:190)
[2023-01-30T11:05:50.159+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:05:50.160+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:05:50.169+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[22] at collect at /opt/***/plugins/scripts/transform_raw_staging.py:190), which has no missing parents
[2023-01-30T11:05:50.193+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 39.3 KiB, free 433.1 MiB)
[2023-01-30T11:05:50.206+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 433.1 MiB)
[2023-01-30T11:05:50.210+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 5b6f5d29e531:35827 (size: 13.4 KiB, free: 434.2 MiB)
[2023-01-30T11:05:50.215+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:05:50.220+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[22] at collect at /opt/***/plugins/scripts/transform_raw_staging.py:190) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:05:50.223+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2023-01-30T11:05:50.231+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
[2023-01-30T11:05:50.234+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
[2023-01-30T11:05:50.429+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO FileScanRDD: Reading File path: gs://entsoe_analytics_1009/total_generation__DE_TENNET__202101010500__202101010600.json, range: 0-9367, partition values: [empty row]
[2023-01-30T11:05:50.708+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2490 bytes result sent to driver
[2023-01-30T11:05:50.712+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 481 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:05:50.713+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2023-01-30T11:05:50.714+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO DAGScheduler: ResultStage 5 (collect at /opt/***/plugins/scripts/transform_raw_staging.py:190) finished in 0.541 s
[2023-01-30T11:05:50.714+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:05:50.715+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2023-01-30T11:05:50.715+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:50 INFO DAGScheduler: Job 5 finished: collect at /opt/***/plugins/scripts/transform_raw_staging.py:190, took 0.560712 s
[2023-01-30T11:05:51.195+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:51 INFO FileSourceStrategy: Pushed Filters:
[2023-01-30T11:05:51.202+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:51 INFO FileSourceStrategy: Post-Scan Filters: (size(cast(GL_MarketDocument#0 as struct<xmlns:string,TimeSeries:array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,quantity_Measure_Unit_name:string>>,createdDateTime:string,mRID:string,process_processType:string,receiver_MarketParticipant_mRID:struct<text:string,codingScheme:string>,receiver_MarketParticipant_marketRole_type:string,revisionNumber:string,sender_MarketParticipant_mRID:struct<text:string,codingScheme:string>,sender_MarketParticipant_marketRole_type:string,time_Period_timeInterval:struct<end:string,start:string>,type:string>).TimeSeries.MktPSRType.psrType, true) > 0),isnotnull(cast(GL_MarketDocument#0 as struct<xmlns:string,TimeSeries:array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,quantity_Measure_Unit_name:string>>,createdDateTime:string,mRID:string,process_processType:string,receiver_MarketParticipant_mRID:struct<text:string,codingScheme:string>,receiver_MarketParticipant_marketRole_type:string,revisionNumber:string,sender_MarketParticipant_mRID:struct<text:string,codingScheme:string>,sender_MarketParticipant_marketRole_type:string,time_Period_timeInterval:struct<end:string,start:string>,type:string>).TimeSeries.MktPSRType.psrType)
[2023-01-30T11:05:51.204+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:51 INFO FileSourceStrategy: Output Data Schema: struct<GL_MarketDocument: struct<@xmlns: string, TimeSeries: array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,quantity_Measure_Unit.name:string>>, createdDateTime: string, mRID: string, process.processType: string ... 10 more fields>>
[2023-01-30T11:05:52.218+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO CodeGenerator: Code generated in 768.931611 ms
[2023-01-30T11:05:52.293+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 201.3 KiB, free 432.9 MiB)
[2023-01-30T11:05:52.435+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 432.9 MiB)
[2023-01-30T11:05:52.436+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 5b6f5d29e531:35827 (size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:05:52.441+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO SparkContext: Created broadcast 12 from collect at /opt/***/plugins/scripts/transform_raw_staging.py:191
[2023-01-30T11:05:52.449+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4203671 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-30T11:05:52.700+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO SparkContext: Starting job: collect at /opt/***/plugins/scripts/transform_raw_staging.py:191
[2023-01-30T11:05:52.702+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO DAGScheduler: Got job 6 (collect at /opt/***/plugins/scripts/transform_raw_staging.py:191) with 1 output partitions
[2023-01-30T11:05:52.702+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO DAGScheduler: Final stage: ResultStage 6 (collect at /opt/***/plugins/scripts/transform_raw_staging.py:191)
[2023-01-30T11:05:52.703+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:05:52.703+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:05:52.710+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at collect at /opt/***/plugins/scripts/transform_raw_staging.py:191), which has no missing parents
[2023-01-30T11:05:52.728+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 36.5 KiB, free 432.9 MiB)
[2023-01-30T11:05:52.760+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 432.8 MiB)
[2023-01-30T11:05:52.767+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 5b6f5d29e531:35827 (size: 12.6 KiB, free: 434.2 MiB)
[2023-01-30T11:05:52.772+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:05:52.778+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at collect at /opt/***/plugins/scripts/transform_raw_staging.py:191) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:05:52.781+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2023-01-30T11:05:52.789+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
[2023-01-30T11:05:52.790+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
[2023-01-30T11:05:52.839+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:52 INFO FileScanRDD: Reading File path: gs://entsoe_analytics_1009/total_generation__DE_TENNET__202101010500__202101010600.json, range: 0-9367, partition values: [empty row]
[2023-01-30T11:05:53.150+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:53 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1784 bytes result sent to driver
[2023-01-30T11:05:53.158+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:53 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 371 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:05:53.164+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:53 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2023-01-30T11:05:53.164+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:53 INFO DAGScheduler: ResultStage 6 (collect at /opt/***/plugins/scripts/transform_raw_staging.py:191) finished in 0.447 s
[2023-01-30T11:05:53.165+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:53 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:05:53.166+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
[2023-01-30T11:05:53.166+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:53 INFO DAGScheduler: Job 6 finished: collect at /opt/***/plugins/scripts/transform_raw_staging.py:191, took 0.461307 s
[2023-01-30T11:05:53.875+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:53 INFO FileSourceStrategy: Pushed Filters:
[2023-01-30T11:05:53.877+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:53 INFO FileSourceStrategy: Post-Scan Filters: (size(cast(GL_MarketDocument#0 as struct<xmlns:string,TimeSeries:array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,quantity_Measure_Unit_name:string>>,createdDateTime:string,mRID:string,process_processType:string,receiver_MarketParticipant_mRID:struct<text:string,codingScheme:string>,receiver_MarketParticipant_marketRole_type:string,revisionNumber:string,sender_MarketParticipant_mRID:struct<text:string,codingScheme:string>,sender_MarketParticipant_marketRole_type:string,time_Period_timeInterval:struct<end:string,start:string>,type:string>).TimeSeries.inBiddingZone_Domain_mRID.text, true) > 0),isnotnull(cast(GL_MarketDocument#0 as struct<xmlns:string,TimeSeries:array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain_mRID:struct<text:string,codingScheme:string>,quantity_Measure_Unit_name:string>>,createdDateTime:string,mRID:string,process_processType:string,receiver_MarketParticipant_mRID:struct<text:string,codingScheme:string>,receiver_MarketParticipant_marketRole_type:string,revisionNumber:string,sender_MarketParticipant_mRID:struct<text:string,codingScheme:string>,sender_MarketParticipant_marketRole_type:string,time_Period_timeInterval:struct<end:string,start:string>,type:string>).TimeSeries.inBiddingZone_Domain_mRID.text)
[2023-01-30T11:05:53.878+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:53 INFO FileSourceStrategy: Output Data Schema: struct<GL_MarketDocument: struct<@xmlns: string, TimeSeries: array<struct<MktPSRType:struct<psrType:string>,Period:struct<Point:array<struct<position:string,quantity:string>>,resolution:string,timeInterval:struct<end:string,start:string>>,businessType:string,curveType:string,inBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,mRID:string,objectAggregation:string,outBiddingZone_Domain.mRID:struct<#text:string,@codingScheme:string>,quantity_Measure_Unit.name:string>>, createdDateTime: string, mRID: string, process.processType: string ... 10 more fields>>
[2023-01-30T11:05:55.728+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:55 INFO CodeGenerator: Code generated in 1032.98101 ms
[2023-01-30T11:05:55.741+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:55 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 201.3 KiB, free 432.7 MiB)
[2023-01-30T11:05:55.785+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:55 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 432.6 MiB)
[2023-01-30T11:05:55.787+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:55 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 5b6f5d29e531:35827 (size: 34.5 KiB, free: 434.1 MiB)
[2023-01-30T11:05:55.789+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:55 INFO SparkContext: Created broadcast 14 from collect at /opt/***/plugins/scripts/transform_raw_staging.py:192
[2023-01-30T11:05:55.792+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4203671 bytes, open cost is considered as scanning 4194304 bytes.
[2023-01-30T11:05:56.022+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO SparkContext: Starting job: collect at /opt/***/plugins/scripts/transform_raw_staging.py:192
[2023-01-30T11:05:56.025+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO DAGScheduler: Got job 7 (collect at /opt/***/plugins/scripts/transform_raw_staging.py:192) with 1 output partitions
[2023-01-30T11:05:56.026+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO DAGScheduler: Final stage: ResultStage 7 (collect at /opt/***/plugins/scripts/transform_raw_staging.py:192)
[2023-01-30T11:05:56.026+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:05:56.027+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:05:56.050+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[30] at collect at /opt/***/plugins/scripts/transform_raw_staging.py:192), which has no missing parents
[2023-01-30T11:05:56.071+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 36.5 KiB, free 432.6 MiB)
[2023-01-30T11:05:56.120+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 432.6 MiB)
[2023-01-30T11:05:56.125+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 5b6f5d29e531:35827 (size: 12.7 KiB, free: 434.1 MiB)
[2023-01-30T11:05:56.132+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:05:56.140+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[30] at collect at /opt/***/plugins/scripts/transform_raw_staging.py:192) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:05:56.148+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
[2023-01-30T11:05:56.151+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
[2023-01-30T11:05:56.155+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
[2023-01-30T11:05:56.213+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO FileScanRDD: Reading File path: gs://entsoe_analytics_1009/total_generation__DE_TENNET__202101010500__202101010600.json, range: 0-9367, partition values: [empty row]
[2023-01-30T11:05:56.477+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1729 bytes result sent to driver
[2023-01-30T11:05:56.483+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 332 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:05:56.494+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2023-01-30T11:05:56.495+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO DAGScheduler: ResultStage 7 (collect at /opt/***/plugins/scripts/transform_raw_staging.py:192) finished in 0.440 s
[2023-01-30T11:05:56.495+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:05:56.496+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2023-01-30T11:05:56.497+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO DAGScheduler: Job 7 finished: collect at /opt/***/plugins/scripts/transform_raw_staging.py:192, took 0.464068 s
[2023-01-30T11:05:56.745+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 5b6f5d29e531:35827 in memory (size: 13.4 KiB, free: 434.1 MiB)
[2023-01-30T11:05:56.907+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 5b6f5d29e531:35827 in memory (size: 12.7 KiB, free: 434.1 MiB)
[2023-01-30T11:05:56.995+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:56 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 5b6f5d29e531:35827 in memory (size: 7.7 KiB, free: 434.1 MiB)
[2023-01-30T11:05:57.058+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:57 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 5b6f5d29e531:35827 in memory (size: 12.6 KiB, free: 434.2 MiB)
[2023-01-30T11:05:57.190+0000] {spark_submit.py:495} INFO - 23/01/30 11:05:57 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 5b6f5d29e531:35827 in memory (size: 12.7 KiB, free: 434.2 MiB)
[2023-01-30T11:06:12.559+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:12 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 5b6f5d29e531:35827 in memory (size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:06:12.670+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:12 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 5b6f5d29e531:35827 in memory (size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:06:12.717+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:12 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 5b6f5d29e531:35827 in memory (size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:06:12.784+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:12 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 5b6f5d29e531:35827 in memory (size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:06:12.827+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:12 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 5b6f5d29e531:35827 in memory (size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:06:12.936+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:12 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 5b6f5d29e531:35827 in memory (size: 34.5 KiB, free: 434.4 MiB)
[2023-01-30T11:06:33.529+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-01-30T11:06:33.652+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-01-30T11:06:33.655+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-01-30T11:06:33.667+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-01-30T11:06:33.672+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-01-30T11:06:33.673+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-01-30T11:06:33.693+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-01-30T11:06:35.323+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO CodeGenerator: Code generated in 22.730552 ms
[2023-01-30T11:06:35.648+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO DAGScheduler: Registering RDD 118 (save at BigQueryWriteHelper.java:105) as input to shuffle 0
[2023-01-30T11:06:35.699+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO DAGScheduler: Got map stage job 8 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:35.709+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:35.716+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:35.728+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:35.763+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[118] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:35.768+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO CodeGenerator: Code generated in 76.191093 ms
[2023-01-30T11:06:35.922+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO CodeGenerator: Code generated in 85.556028 ms
[2023-01-30T11:06:35.948+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 11.1 KiB, free 434.2 MiB)
[2023-01-30T11:06:35.964+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.2 MiB)
[2023-01-30T11:06:35.967+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO CodeGenerator: Code generated in 21.683826 ms
[2023-01-30T11:06:35.972+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 5b6f5d29e531:35827 (size: 5.7 KiB, free: 434.4 MiB)
[2023-01-30T11:06:35.973+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:35.987+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[118] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:35.989+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:35 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2023-01-30T11:06:36.011+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Registering RDD 120 (save at BigQueryWriteHelper.java:105) as input to shuffle 1
[2023-01-30T11:06:36.012+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Got map stage job 9 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:36.017+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:36.019+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:36.021+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:36.024+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7660 bytes) taskResourceAssignments Map()
[2023-01-30T11:06:36.035+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
[2023-01-30T11:06:36.046+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[120] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:36.153+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO CodeGenerator: Code generated in 113.776499 ms
[2023-01-30T11:06:36.191+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 15.6 KiB, free 434.1 MiB)
[2023-01-30T11:06:36.209+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.1 MiB)
[2023-01-30T11:06:36.216+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.4 MiB)
[2023-01-30T11:06:36.218+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:36.220+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[120] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:36.224+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2023-01-30T11:06:36.235+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Registering RDD 122 (save at BigQueryWriteHelper.java:105) as input to shuffle 2
[2023-01-30T11:06:36.236+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Got map stage job 10 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:36.236+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:36.236+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:36.237+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:36.258+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[122] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:36.334+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO CodeGenerator: Code generated in 109.938521 ms
[2023-01-30T11:06:36.359+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 15.7 KiB, free 434.1 MiB)
[2023-01-30T11:06:36.375+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.1 MiB)
[2023-01-30T11:06:36.389+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:36.392+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:36.399+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[122] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:36.400+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2023-01-30T11:06:36.428+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Registering RDD 124 (save at BigQueryWriteHelper.java:105) as input to shuffle 3
[2023-01-30T11:06:36.428+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Got map stage job 11 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:36.429+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:36.429+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:36.429+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:36.441+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[124] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:36.635+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO CodeGenerator: Code generated in 200.445965 ms
[2023-01-30T11:06:36.635+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 15.7 KiB, free 434.1 MiB)
[2023-01-30T11:06:36.638+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO CodeGenerator: Code generated in 259.866413 ms
[2023-01-30T11:06:36.647+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.1 MiB)
[2023-01-30T11:06:36.657+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:36.662+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:36.674+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[124] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:36.677+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2023-01-30T11:06:36.731+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Registering RDD 126 (save at BigQueryWriteHelper.java:105) as input to shuffle 4
[2023-01-30T11:06:36.752+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Got map stage job 12 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:36.754+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:36.755+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:36.755+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:36.806+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[126] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:36.864+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 15.7 KiB, free 434.1 MiB)
[2023-01-30T11:06:36.893+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.1 MiB)
[2023-01-30T11:06:36.895+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:36.896+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:36.917+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[126] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:36.918+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2023-01-30T11:06:36.934+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Registering RDD 128 (save at BigQueryWriteHelper.java:105) as input to shuffle 5
[2023-01-30T11:06:36.939+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Got map stage job 13 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:36.943+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:36.945+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO CodeGenerator: Code generated in 143.159642 ms
[2023-01-30T11:06:36.946+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:36.946+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:36.972+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:36 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[128] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:37.054+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 15.7 KiB, free 434.0 MiB)
[2023-01-30T11:06:37.070+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.0 MiB)
[2023-01-30T11:06:37.074+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:37.079+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:37.087+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[128] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:37.089+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2023-01-30T11:06:37.098+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Registering RDD 130 (save at BigQueryWriteHelper.java:105) as input to shuffle 6
[2023-01-30T11:06:37.104+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Got map stage job 14 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:37.106+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:37.108+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:37.115+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:37.124+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[130] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:37.192+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO CodeGenerator: Code generated in 110.259231 ms
[2023-01-30T11:06:37.229+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 15.7 KiB, free 434.0 MiB)
[2023-01-30T11:06:37.261+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.0 MiB)
[2023-01-30T11:06:37.263+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:37.267+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:37.277+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[130] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:37.283+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2023-01-30T11:06:37.295+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Registering RDD 132 (save at BigQueryWriteHelper.java:105) as input to shuffle 7
[2023-01-30T11:06:37.323+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Got map stage job 15 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:37.330+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:37.331+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:37.332+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:37.394+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[132] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:37.594+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 15.7 KiB, free 434.0 MiB)
[2023-01-30T11:06:37.607+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO CodeGenerator: Code generated in 280.193925 ms
[2023-01-30T11:06:37.901+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2087 bytes result sent to driver
[2023-01-30T11:06:37.906+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.0 MiB)
[2023-01-30T11:06:37.942+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:06:37.958+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:37.980+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:37.981+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[132] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:37.981+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2023-01-30T11:06:37.989+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 1996 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:06:37.989+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2023-01-30T11:06:37.991+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:37 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
[2023-01-30T11:06:38.078+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Registering RDD 134 (save at BigQueryWriteHelper.java:105) as input to shuffle 8
[2023-01-30T11:06:38.104+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Got map stage job 16 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:38.104+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:38.105+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:38.105+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:38.151+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[134] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:38.348+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO CodeGenerator: Code generated in 276.243629 ms
[2023-01-30T11:06:38.361+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 15.7 KiB, free 434.0 MiB)
[2023-01-30T11:06:38.394+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.0 MiB)
[2023-01-30T11:06:38.491+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:38.512+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:38.543+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[134] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:38.550+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2023-01-30T11:06:38.556+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Registering RDD 136 (save at BigQueryWriteHelper.java:105) as input to shuffle 9
[2023-01-30T11:06:38.556+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Got map stage job 17 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:38.557+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Final stage: ShuffleMapStage 17 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:38.557+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:38.557+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:38.747+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[136] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:38.782+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 15.7 KiB, free 434.0 MiB)
[2023-01-30T11:06:38.831+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 433.9 MiB)
[2023-01-30T11:06:38.856+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:38.899+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:38.899+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[136] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:38.900+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2023-01-30T11:06:38.973+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:38 INFO CodeGenerator: Code generated in 349.49876 ms
[2023-01-30T11:06:39.009+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: ShuffleMapStage 8 (save at BigQueryWriteHelper.java:105) finished in 3.238 s
[2023-01-30T11:06:39.053+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:06:39.054+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: running: HashSet(ShuffleMapStage 16, ShuffleMapStage 17, ShuffleMapStage 9, ShuffleMapStage 10, ShuffleMapStage 11, ShuffleMapStage 12, ShuffleMapStage 13, ShuffleMapStage 14, ShuffleMapStage 15)
[2023-01-30T11:06:39.055+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:06:39.057+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:06:39.151+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Registering RDD 138 (save at BigQueryWriteHelper.java:105) as input to shuffle 10
[2023-01-30T11:06:39.151+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Got map stage job 18 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:39.153+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Final stage: ShuffleMapStage 18 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:39.153+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:39.154+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:39.200+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[138] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:39.226+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 15.7 KiB, free 433.9 MiB)
[2023-01-30T11:06:39.287+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 433.9 MiB)
[2023-01-30T11:06:39.291+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:39.300+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:39.303+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[138] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:39.318+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2023-01-30T11:06:39.365+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Registering RDD 140 (save at BigQueryWriteHelper.java:105) as input to shuffle 11
[2023-01-30T11:06:39.366+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Got map stage job 19 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:39.367+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:39.367+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:39.407+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:39.415+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO CodeGenerator: Code generated in 180.967523 ms
[2023-01-30T11:06:39.491+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[140] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:39.766+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:39 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 15.7 KiB, free 433.9 MiB)
[2023-01-30T11:06:40.065+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 433.9 MiB)
[2023-01-30T11:06:40.069+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:40.070+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:40.116+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[140] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:40.117+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
[2023-01-30T11:06:40.122+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Registering RDD 142 (save at BigQueryWriteHelper.java:105) as input to shuffle 12
[2023-01-30T11:06:40.191+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO CodeGenerator: Code generated in 512.487291 ms
[2023-01-30T11:06:40.193+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Got map stage job 20 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:40.194+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Final stage: ShuffleMapStage 20 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:40.194+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:40.195+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:40.261+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[142] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:40.330+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 15.7 KiB, free 433.9 MiB)
[2023-01-30T11:06:40.519+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 433.9 MiB)
[2023-01-30T11:06:40.557+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:40.559+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:40.561+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[142] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:40.563+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2023-01-30T11:06:40.567+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Registering RDD 144 (save at BigQueryWriteHelper.java:105) as input to shuffle 13
[2023-01-30T11:06:40.569+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Got map stage job 21 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:40.570+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Final stage: ShuffleMapStage 21 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:40.582+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:40.583+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:40.605+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[144] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:40.678+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 15.7 KiB, free 433.9 MiB)
[2023-01-30T11:06:40.687+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO CodeGenerator: Code generated in 134.830698 ms
[2023-01-30T11:06:40.973+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 433.9 MiB)
[2023-01-30T11:06:40.983+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:40.988+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:40.991+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[144] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:41.072+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
[2023-01-30T11:06:41.104+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO DAGScheduler: Registering RDD 146 (save at BigQueryWriteHelper.java:105) as input to shuffle 14
[2023-01-30T11:06:41.106+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO DAGScheduler: Got map stage job 22 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:41.107+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:41.206+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:41.208+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:41.213+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 5b6f5d29e531:35827 in memory (size: 5.7 KiB, free: 434.3 MiB)
[2023-01-30T11:06:41.287+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[146] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:41.446+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 15.7 KiB, free 433.9 MiB)
[2023-01-30T11:06:41.450+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 433.8 MiB)
[2023-01-30T11:06:41.454+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:06:41.456+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:41.459+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[146] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:41.541+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2023-01-30T11:06:41.751+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:41 INFO CodeGenerator: Code generated in 621.627484 ms
[2023-01-30T11:06:42.101+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Registering RDD 148 (save at BigQueryWriteHelper.java:105) as input to shuffle 15
[2023-01-30T11:06:42.102+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Got map stage job 23 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:42.102+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Final stage: ShuffleMapStage 23 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:42.103+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:42.103+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:42.191+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[148] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:42.334+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 15.7 KiB, free 433.8 MiB)
[2023-01-30T11:06:42.418+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 433.8 MiB)
[2023-01-30T11:06:42.421+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:06:42.450+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:42.503+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[148] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:42.507+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
[2023-01-30T11:06:42.646+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO CodeGenerator: Code generated in 305.955361 ms
[2023-01-30T11:06:42.787+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Registering RDD 150 (save at BigQueryWriteHelper.java:105) as input to shuffle 16
[2023-01-30T11:06:42.788+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Got map stage job 24 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:06:42.788+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Final stage: ShuffleMapStage 24 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:06:42.791+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:06:42.795+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:06:42.911+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[150] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:06:42.993+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:42 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 15.7 KiB, free 433.8 MiB)
[2023-01-30T11:06:43.042+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:43 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 433.8 MiB)
[2023-01-30T11:06:43.073+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:43 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:06:43.078+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:43 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:06:43.078+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[150] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:06:43.079+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:43 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
[2023-01-30T11:06:46.016+0000] {spark_submit.py:495} INFO - 23/01/30 11:06:46 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2023-01-30T11:07:34.520+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:34 INFO CodeGenerator: Code generated in 6086.77488 ms
[2023-01-30T11:07:53.639+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:53 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2023-01-30T11:07:54.145+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO DAGScheduler: Got job 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2023-01-30T11:07:54.145+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO DAGScheduler: Final stage: ResultStage 26 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2023-01-30T11:07:54.145+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
[2023-01-30T11:07:54.156+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:07:54.225+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[154] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2023-01-30T11:07:54.502+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 21.6 KiB, free 433.8 MiB)
[2023-01-30T11:07:54.511+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 10.2 KiB, free 433.8 MiB)
[2023-01-30T11:07:54.512+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:07:54.512+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:07:54.513+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[154] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:07:54.514+0000] {spark_submit.py:495} INFO - 23/01/30 11:07:54 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
[2023-01-30T11:08:14.170+0000] {base_job.py:232} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3361, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 325, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 888, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 491, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 271, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 386, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 684, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 210, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 680, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/base_job.py", line 204, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 3051, in merge
    return self._merge(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 3131, in _merge
    merged = self.get(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2848, in get
    return self._get_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2970, in _get_impl
    return db_load_fn(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1713, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1552, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3315, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3394, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3364, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2198, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 210, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3361, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 325, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 888, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 491, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 271, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 386, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 684, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 210, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 680, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-01-30T11:08:16.584+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:16 INFO CodeGenerator: Code generated in 456.070419 ms
[2023-01-30T11:08:19.866+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:19 INFO PythonRunner: Times: total = 99482, boot = 96496, init = 2982, finish = 4
[2023-01-30T11:08:21.283+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2521 bytes result sent to driver
[2023-01-30T11:08:21.350+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:08:21.354+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 103413 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:08:21.358+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2023-01-30T11:08:21.407+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
[2023-01-30T11:08:21.432+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 44667
[2023-01-30T11:08:21.656+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO DAGScheduler: ShuffleMapStage 9 (save at BigQueryWriteHelper.java:105) finished in 105.532 s
[2023-01-30T11:08:21.658+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:08:21.658+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO DAGScheduler: running: HashSet(ShuffleMapStage 10, ShuffleMapStage 11, ShuffleMapStage 12, ShuffleMapStage 13, ShuffleMapStage 14, ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 17, ShuffleMapStage 18, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:08:21.658+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:08:21.659+0000] {spark_submit.py:495} INFO - 23/01/30 11:08:21 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:09:11.026+0000] {base_job.py:232} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3361, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 325, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 888, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 491, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 271, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 386, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 684, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 210, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 680, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/base_job.py", line 228, in heartbeat
    self.heartbeat_callback(session=session)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/local_task_job.py", line 178, in heartbeat_callback
    self.task_instance.refresh_from_db()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 795, in refresh_from_db
    ti = qry.one_or_none()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2849, in one_or_none
    return self._iter().one_or_none()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2915, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1713, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1552, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3315, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3394, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3364, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2198, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 210, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3361, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 325, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 888, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 491, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 271, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 386, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 684, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 210, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 680, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-01-30T11:11:03.614+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:03 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 139940 ms exceeds timeout 120000 ms
[2023-01-30T11:11:03.537+0000] {base_job.py:232} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3361, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 325, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 888, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 491, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 271, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 386, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 684, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 210, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 680, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/base_job.py", line 204, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 3051, in merge
    return self._merge(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 3131, in _merge
    merged = self.get(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2848, in get
    return self._get_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2970, in _get_impl
    return db_load_fn(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1713, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1552, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3315, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3394, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3364, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2198, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 210, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3361, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 325, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 888, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 491, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 271, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 386, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 684, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 210, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 680, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-01-30T11:11:04.195+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 WARN SparkContext: Killing executors is not supported by current scheduler.
[2023-01-30T11:11:04.200+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:04.200+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:04.201+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:04.274+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:04.275+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:04.661+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:04.773+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:04.829+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:04.862+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO PythonRunner: Times: total = 17748, boot = -2309, init = 20027, finish = 30
[2023-01-30T11:11:04.874+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:04.884+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:04.900+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:04.960+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:04.969+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:04.972+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:04.974+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:04 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.005+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.008+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.011+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.014+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.017+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.080+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.083+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.085+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.088+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:05.088+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:05.088+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:05.090+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:05.091+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:05.092+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.094+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.098+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.100+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.102+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.104+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.106+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.128+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.131+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.142+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.149+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.178+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.183+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.185+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.188+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.190+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.194+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.208+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.359+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:05.360+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:05.360+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:05.372+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:05.372+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:05.387+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.399+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2478 bytes result sent to driver
[2023-01-30T11:11:05.399+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:11:05.399+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 164051 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:11:05.400+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2023-01-30T11:11:05.404+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
[2023-01-30T11:11:05.521+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.529+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO DAGScheduler: ShuffleMapStage 10 (save at BigQueryWriteHelper.java:105) finished in 269.155 s
[2023-01-30T11:11:05.529+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:11:05.530+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO DAGScheduler: running: HashSet(ShuffleMapStage 11, ShuffleMapStage 12, ShuffleMapStage 13, ShuffleMapStage 14, ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 17, ShuffleMapStage 18, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:11:05.530+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:11:05.530+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:11:05.530+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.530+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.530+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.531+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.727+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.741+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.747+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.752+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.796+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.805+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.876+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.878+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.881+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.926+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.941+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.942+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:05.977+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:05.977+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:05.977+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:05.996+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:05.996+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:05 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:06.008+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.014+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.036+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.058+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.058+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.059+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.063+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.181+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.181+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.207+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.235+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.237+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.261+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.275+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.276+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.280+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.315+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.317+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.322+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:06.322+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:06.322+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:06.322+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO PythonRunner: Times: total = 763, boot = -145808, init = 146571, finish = 0
[2023-01-30T11:11:06.327+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:06.327+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:06.329+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.338+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.350+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.353+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.359+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.366+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.367+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.369+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.370+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.371+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.373+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.374+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.375+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.376+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.378+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.379+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.383+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.395+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.398+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:06.399+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:06.409+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:06.409+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:06.409+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:06.410+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.410+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.410+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.429+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.433+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.433+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.436+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.437+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.445+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.449+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.449+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.449+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.449+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.449+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.450+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.450+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.450+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.450+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.450+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:06.451+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:06.451+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:06.452+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:06.452+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:06.453+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.453+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.453+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.453+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.453+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.454+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.454+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.454+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.454+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.454+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.454+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.455+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.455+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.455+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.455+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.455+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.456+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.456+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.456+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:06.456+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:06.456+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:06.456+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:06.457+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:06.457+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.457+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.457+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.457+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.458+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.460+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.464+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.467+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.469+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.471+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.473+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.474+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.476+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.477+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.478+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.479+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.480+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.482+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.484+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:06.485+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:06.485+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:06.496+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2478 bytes result sent to driver
[2023-01-30T11:11:06.496+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:11:06.496+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 1097 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:11:06.497+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2023-01-30T11:11:06.497+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO DAGScheduler: ShuffleMapStage 11 (save at BigQueryWriteHelper.java:105) finished in 270.057 s
[2023-01-30T11:11:06.497+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:11:06.497+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO DAGScheduler: running: HashSet(ShuffleMapStage 12, ShuffleMapStage 13, ShuffleMapStage 14, ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 17, ShuffleMapStage 18, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:11:06.497+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:11:06.498+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:11:06.502+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
[2023-01-30T11:11:06.509+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:06.510+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:06.513+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.514+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.517+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.530+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.533+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.535+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.537+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.632+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.640+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.641+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.642+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.643+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.644+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.645+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.717+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.778+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.784+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:06.785+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:06 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.082+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:07.094+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:07.095+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:07.109+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:07.110+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:07.119+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.126+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO PythonRunner: Times: total = 270, boot = -160, init = 430, finish = 0
[2023-01-30T11:11:07.150+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.152+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.153+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.155+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.157+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.166+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.184+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.259+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.261+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.262+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.262+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2478 bytes result sent to driver
[2023-01-30T11:11:07.263+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:11:07.267+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 772 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:11:07.267+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
[2023-01-30T11:11:07.270+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2023-01-30T11:11:07.270+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO DAGScheduler: ShuffleMapStage 12 (save at BigQueryWriteHelper.java:105) finished in 270.463 s
[2023-01-30T11:11:07.270+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:11:07.380+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.381+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.382+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.387+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO DAGScheduler: running: HashSet(ShuffleMapStage 13, ShuffleMapStage 14, ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 17, ShuffleMapStage 18, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:11:07.388+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:11:07.388+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:11:07.412+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.416+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.417+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.418+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.568+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:07.569+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:07.569+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:07.571+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:07.571+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:07.571+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.573+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.573+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.587+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.588+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.588+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.595+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.595+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.609+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.648+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.652+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.659+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.660+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.672+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.679+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.680+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.681+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.682+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.685+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:07.685+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:07.685+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:07.720+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:07.727+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:07.728+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.728+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.728+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.728+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.832+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.834+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.836+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.841+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.857+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.866+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.870+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.880+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.886+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.891+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.897+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.905+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.915+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.917+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.925+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:07.925+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:07.926+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:07.931+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:07.932+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:07.934+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.948+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.957+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.969+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.980+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.982+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:07.993+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:07 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.033+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.036+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.110+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.128+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.152+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.198+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.221+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.277+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.300+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.302+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.304+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:08.312+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:08.312+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:08.313+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:08.946+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:08.955+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:08 INFO BlockManager: Reporting 36 blocks to the master.
[2023-01-30T11:11:09.065+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_20_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.068+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.069+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_18_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.100+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.136+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.150+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.160+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.162+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.167+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.168+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.176+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.184+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.185+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.191+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.208+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.211+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.212+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.217+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.234+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_19_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.251+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:09.251+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:09.252+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:09.253+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:09.254+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManager: Reporting 34 blocks to the master.
[2023-01-30T11:11:09.254+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.268+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.308+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.2 MiB)
[2023-01-30T11:11:09.336+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.344+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.346+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.347+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.375+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.377+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_17_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.382+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.384+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.384+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.385+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.394+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.450+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.453+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.454+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.456+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.495+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:09.495+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:09.496+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:09.496+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:09.497+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManager: Reporting 28 blocks to the master.
[2023-01-30T11:11:09.498+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.499+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.508+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.509+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.512+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.513+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.515+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.517+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.520+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.522+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.524+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.525+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.527+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.530+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:11:09.934+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO PythonRunner: Times: total = 2300, boot = -594, init = 2893, finish = 1
[2023-01-30T11:11:09.980+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2521 bytes result sent to driver
[2023-01-30T11:11:09.984+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:11:09.989+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 2723 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:11:09.989+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2023-01-30T11:11:09.989+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO DAGScheduler: ShuffleMapStage 13 (save at BigQueryWriteHelper.java:105) finished in 273.011 s
[2023-01-30T11:11:09.990+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:11:09.990+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO DAGScheduler: running: HashSet(ShuffleMapStage 14, ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 17, ShuffleMapStage 18, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:11:09.990+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:11:09.990+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:09 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:11:10.015+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:10 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
[2023-01-30T11:11:11.332+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO PythonRunner: Times: total = 679, boot = -241, init = 915, finish = 5
[2023-01-30T11:11:11.718+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 2478 bytes result sent to driver
[2023-01-30T11:11:11.737+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:11:11.737+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
[2023-01-30T11:11:11.739+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 1756 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:11:11.739+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2023-01-30T11:11:11.748+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO DAGScheduler: ShuffleMapStage 14 (save at BigQueryWriteHelper.java:105) finished in 274.621 s
[2023-01-30T11:11:11.749+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:11:11.749+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO DAGScheduler: running: HashSet(ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 17, ShuffleMapStage 18, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:11:11.749+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:11:11.749+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:11 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:11:12.795+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:12 INFO PythonRunner: Times: total = 971, boot = -804, init = 1775, finish = 0
[2023-01-30T11:11:13.329+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:13 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2478 bytes result sent to driver
[2023-01-30T11:11:13.331+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:13 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:11:13.336+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:13 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
[2023-01-30T11:11:13.340+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:13 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 1608 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:11:13.340+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:13 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2023-01-30T11:11:13.344+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:13 INFO DAGScheduler: ShuffleMapStage 15 (save at BigQueryWriteHelper.java:105) finished in 275.950 s
[2023-01-30T11:11:13.344+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:13 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:11:13.344+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:13 INFO DAGScheduler: running: HashSet(ShuffleMapStage 16, ShuffleMapStage 17, ShuffleMapStage 18, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:11:13.344+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:13 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:11:13.344+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:13 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:11:18.398+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:18 INFO PythonRunner: Times: total = 1416, boot = -602, init = 2016, finish = 2
[2023-01-30T11:11:19.001+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:19 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2521 bytes result sent to driver
[2023-01-30T11:11:19.014+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:19 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:11:19.034+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:19 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
[2023-01-30T11:11:19.038+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:19 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 5706 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:11:19.039+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:19 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2023-01-30T11:11:19.049+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:19 INFO DAGScheduler: ShuffleMapStage 16 (save at BigQueryWriteHelper.java:105) finished in 280.833 s
[2023-01-30T11:11:19.050+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:19 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:11:19.050+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:19 INFO DAGScheduler: running: HashSet(ShuffleMapStage 17, ShuffleMapStage 18, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:11:19.053+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:19 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:11:19.079+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:19 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:11:21.122+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:21.191+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:21.191+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:21.192+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:21.192+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManager: Reporting 28 blocks to the master.
[2023-01-30T11:11:21.193+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.193+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.193+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.219+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.220+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.220+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.221+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.221+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.222+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.222+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.222+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.222+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.223+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:21.324+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:21 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:11:26.473+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO PythonRunner: Times: total = 4048, boot = -2984, init = 7032, finish = 0
[2023-01-30T11:11:26.616+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2521 bytes result sent to driver
[2023-01-30T11:11:26.631+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:11:26.657+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 7643 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:11:26.669+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
[2023-01-30T11:11:26.679+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2023-01-30T11:11:26.679+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO DAGScheduler: ShuffleMapStage 17 (save at BigQueryWriteHelper.java:105) finished in 287.933 s
[2023-01-30T11:11:26.680+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:11:26.680+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO DAGScheduler: running: HashSet(ShuffleMapStage 18, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:11:26.680+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:11:26.681+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:26 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:11:31.905+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:31 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:31.935+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:31 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:31.936+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:31.937+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:31.937+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:31 INFO BlockManager: Reporting 28 blocks to the master.
[2023-01-30T11:11:33.300+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:33 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:33.877+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:33 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:33.948+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:33 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:34.900+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:34 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.021+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.025+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.026+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.028+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.033+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.035+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.038+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.040+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.043+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.046+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:11:35.522+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:35 INFO PythonRunner: Times: total = 5645, boot = -3558, init = 9202, finish = 1
[2023-01-30T11:11:38.563+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:38 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2521 bytes result sent to driver
[2023-01-30T11:11:39.383+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:39 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:11:39.724+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:39 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 12837 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:11:39.724+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:39 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2023-01-30T11:11:39.725+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:39 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
[2023-01-30T11:11:39.727+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:39 INFO DAGScheduler: ShuffleMapStage 18 (save at BigQueryWriteHelper.java:105) finished in 300.386 s
[2023-01-30T11:11:39.727+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:39 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:11:39.728+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:39 INFO DAGScheduler: running: HashSet(ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:11:39.816+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:39 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:11:39.816+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:39 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:11:41.978+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:41 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:11:42.041+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:41 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:11:42.041+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:42.071+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:11:42.071+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:42 INFO BlockManager: Reporting 28 blocks to the master.
[2023-01-30T11:11:42.604+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:42 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:11:53.098+0000] {spark_submit.py:495} INFO - 23/01/30 11:11:46 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:01.439+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:01 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.371+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.513+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.515+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.516+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.752+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.754+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.758+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.800+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.842+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.862+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:04.876+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:04 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:06.400+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:06 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:12:06.463+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:06 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:12:06.464+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:06.866+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:07.467+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:06 INFO BlockManager: Reporting 28 blocks to the master.
[2023-01-30T11:12:07.482+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.492+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.501+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.503+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.523+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.715+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.738+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.835+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.846+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.852+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.854+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.856+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:07.982+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:07 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:08.224+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:08 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.065+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:12:40.069+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:12:40.073+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:40.075+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:40.076+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManager: Reporting 28 blocks to the master.
[2023-01-30T11:12:40.078+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.081+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.086+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.089+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.101+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.102+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.102+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.102+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.103+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.104+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.106+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.110+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.110+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.111+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.114+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:12:40.114+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:12:40.115+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:40.116+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:40.116+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManager: Reporting 28 blocks to the master.
[2023-01-30T11:12:40.117+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.117+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.118+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.119+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.121+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.122+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.123+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.125+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.126+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.128+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.130+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.132+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.144+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.270+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.383+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:12:40.388+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:12:40.389+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:40.407+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO PythonRunner: Times: total = 24265, boot = -9435, init = 33699, finish = 1
[2023-01-30T11:12:40.609+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:40.610+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManager: Reporting 28 blocks to the master.
[2023-01-30T11:12:40.714+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.829+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:40.885+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:40 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.172+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.174+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.177+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.180+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.182+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.205+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.224+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.227+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.245+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.350+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.365+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.366+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:12:41.366+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:12:41.366+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:41.438+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 2478 bytes result sent to driver
[2023-01-30T11:12:41.457+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:41.458+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManager: Reporting 28 blocks to the master.
[2023-01-30T11:12:41.461+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:12:41.461+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.464+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.465+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.466+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.472+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.473+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 62543 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:12:41.473+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2023-01-30T11:12:41.505+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
[2023-01-30T11:12:41.505+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO DAGScheduler: ShuffleMapStage 19 (save at BigQueryWriteHelper.java:105) finished in 361.927 s
[2023-01-30T11:12:41.506+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:12:41.506+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO DAGScheduler: running: HashSet(ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:12:41.506+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:12:41.572+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:12:41.573+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.573+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.574+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.574+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.574+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.574+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.730+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.738+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.739+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.852+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:12:41.860+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:12:41.860+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:41.862+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:41.893+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManager: Reporting 28 blocks to the master.
[2023-01-30T11:12:41.894+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_24_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.894+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_29_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.932+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_23_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:41.933+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_25_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:42.103+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:41 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:42.145+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:42 INFO BlockManagerInfo: Updated broadcast_28_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:42.145+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:42 INFO BlockManagerInfo: Updated broadcast_22_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:42.146+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:42 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:12:42.146+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:42 INFO BlockManagerInfo: Updated broadcast_21_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:42.146+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:42 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:42.146+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:42 INFO BlockManagerInfo: Updated broadcast_27_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:42.147+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:42 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:42.192+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:42 INFO BlockManagerInfo: Updated broadcast_26_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:42.192+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:42 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:44.464+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO PythonRunner: Times: total = 2584, boot = -33205, init = 35789, finish = 0
[2023-01-30T11:12:44.478+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 2478 bytes result sent to driver
[2023-01-30T11:12:44.487+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:12:44.496+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 3034 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:12:44.497+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2023-01-30T11:12:44.497+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO DAGScheduler: ShuffleMapStage 20 (save at BigQueryWriteHelper.java:105) finished in 364.240 s
[2023-01-30T11:12:44.498+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:12:44.498+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO DAGScheduler: running: HashSet(ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:12:44.498+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:12:44.521+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:12:44.571+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:44 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
[2023-01-30T11:12:47.172+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO PythonRunner: Times: total = 2321, boot = -357, init = 2678, finish = 0
[2023-01-30T11:12:47.211+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 2478 bytes result sent to driver
[2023-01-30T11:12:47.218+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:12:47.227+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 2739 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:12:47.231+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool
[2023-01-30T11:12:47.231+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO DAGScheduler: ShuffleMapStage 21 (save at BigQueryWriteHelper.java:105) finished in 366.619 s
[2023-01-30T11:12:47.232+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:12:47.233+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO DAGScheduler: running: HashSet(ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:12:47.235+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:12:47.237+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:12:47.240+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
[2023-01-30T11:12:47.948+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:47 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:48.080+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:48.188+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:48.248+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:48.296+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:48.398+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:48.516+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:48.592+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO PythonRunner: Times: total = 1205, boot = -103, init = 1307, finish = 1
[2023-01-30T11:12:48.621+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:48.635+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 2521 bytes result sent to driver
[2023-01-30T11:12:48.662+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:12:48.673+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
[2023-01-30T11:12:48.680+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 1457 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:12:48.681+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2023-01-30T11:12:48.681+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO DAGScheduler: ShuffleMapStage 22 (save at BigQueryWriteHelper.java:105) finished in 367.392 s
[2023-01-30T11:12:48.681+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:12:48.682+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO DAGScheduler: running: HashSet(ShuffleMapStage 23, ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:12:48.682+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:12:48.682+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:12:48.816+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:48 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:49.622+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:49 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:12:49.623+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:49 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:12:49.623+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:49.633+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:49.635+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:49 INFO BlockManager: Reporting 10 blocks to the master.
[2023-01-30T11:12:49.696+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:49 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:49.697+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:49 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:12:49.716+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:49 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:49.718+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:49 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:49.719+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:49 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:50.406+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO PythonRunner: Times: total = 1644, boot = 29, init = 1615, finish = 0
[2023-01-30T11:12:50.454+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2478 bytes result sent to driver
[2023-01-30T11:12:50.463+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:12:50.464+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 1786 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:12:50.473+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO DAGScheduler: ShuffleMapStage 23 (save at BigQueryWriteHelper.java:105) finished in 368.264 s
[2023-01-30T11:12:50.484+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:12:50.490+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO DAGScheduler: running: HashSet(ShuffleMapStage 24, ResultStage 26)
[2023-01-30T11:12:50.493+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:12:50.499+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:12:50.517+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool
[2023-01-30T11:12:50.520+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:50 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
[2023-01-30T11:12:52.310+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO PythonRunner: Times: total = 1364, boot = -463, init = 1827, finish = 0
[2023-01-30T11:12:52.386+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 2521 bytes result sent to driver
[2023-01-30T11:12:52.403+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 25) (5b6f5d29e531, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
[2023-01-30T11:12:52.418+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 1972 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:12:52.424+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool
[2023-01-30T11:12:52.425+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO DAGScheduler: ShuffleMapStage 24 (save at BigQueryWriteHelper.java:105) finished in 369.519 s
[2023-01-30T11:12:52.435+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:12:52.437+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO Executor: Running task 0.0 in stage 26.0 (TID 25)
[2023-01-30T11:12:52.439+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO DAGScheduler: running: HashSet(ResultStage 26)
[2023-01-30T11:12:52.472+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:12:52.494+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:52 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:12:54.196+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:54 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:12:54.255+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 269 ms
[2023-01-30T11:12:55.025+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:55 INFO CodeGenerator: Code generated in 558.321656 ms
[2023-01-30T11:12:55.294+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:55 INFO CodeGenerator: Code generated in 184.850789 ms
[2023-01-30T11:12:55.677+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:55 INFO CodeGenerator: Code generated in 138.387584 ms
[2023-01-30T11:12:55.792+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:55 INFO CodeGenerator: Code generated in 112.081545 ms
[2023-01-30T11:12:57.751+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:57 INFO CodeGenerator: Code generated in 258.809032 ms
[2023-01-30T11:12:58.003+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO CodeGenerator: Code generated in 174.671919 ms
[2023-01-30T11:12:58.209+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO CodeGenerator: Code generated in 147.108832 ms
[2023-01-30T11:12:58.359+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO Executor: Finished task 0.0 in stage 26.0 (TID 25). 3174 bytes result sent to driver
[2023-01-30T11:12:58.370+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 25) in 5970 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:12:58.371+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool
[2023-01-30T11:12:58.371+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO DAGScheduler: ResultStage 26 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 303.919 s
[2023-01-30T11:12:58.372+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:12:58.372+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
[2023-01-30T11:12:58.372+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO DAGScheduler: Job 25 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 304.734143 s
[2023-01-30T11:12:58.512+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO CodeGenerator: Code generated in 51.878299 ms
[2023-01-30T11:12:58.544+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 1024.1 KiB, free 433.1 MiB)
[2023-01-30T11:12:58.660+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 279.0 B, free 433.1 MiB)
[2023-01-30T11:12:58.661+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (size: 279.0 B, free: 434.3 MiB)
[2023-01-30T11:12:58.662+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:58 INFO SparkContext: Created broadcast 34 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2023-01-30T11:12:59.108+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO CodeGenerator: Code generated in 21.431575 ms
[2023-01-30T11:12:59.202+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO DAGScheduler: Registering RDD 156 (save at BigQueryWriteHelper.java:105) as input to shuffle 17
[2023-01-30T11:12:59.203+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO DAGScheduler: Got map stage job 26 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:12:59.203+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:12:59.203+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO DAGScheduler: Parents of final stage: List()
[2023-01-30T11:12:59.204+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:12:59.208+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[156] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:12:59.432+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 18.1 KiB, free 433.1 MiB)
[2023-01-30T11:12:59.434+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 433.0 MiB)
[2023-01-30T11:12:59.435+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 5b6f5d29e531:35827 (size: 9.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:59.493+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:12:59.494+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:12:59.494+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:59.495+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:12:59.496+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManager: Reporting 14 blocks to the master.
[2023-01-30T11:12:59.509+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:12:59.509+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManagerInfo: Updated broadcast_30_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:59.512+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:12:59.516+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManagerInfo: Updated broadcast_32_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:59.518+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManagerInfo: Updated broadcast_31_piece0 in memory on 5b6f5d29e531:35827 (current size: 8.1 KiB, original size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:12:59.541+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManagerInfo: Updated broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (current size: 279.0 B, original size: 279.0 B, free: 434.3 MiB)
[2023-01-30T11:12:59.544+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManagerInfo: Updated broadcast_35_piece0 in memory on 5b6f5d29e531:35827 (current size: 9.2 KiB, original size: 9.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:59.546+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO BlockManagerInfo: Updated broadcast_33_piece0 in memory on 5b6f5d29e531:35827 (current size: 10.2 KiB, original size: 10.2 KiB, free: 434.3 MiB)
[2023-01-30T11:12:59.553+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[156] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:12:59.553+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
[2023-01-30T11:12:59.554+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 26) (5b6f5d29e531, executor driver, partition 0, PROCESS_LOCAL, 7510 bytes) taskResourceAssignments Map()
[2023-01-30T11:12:59.554+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO Executor: Running task 0.0 in stage 27.0 (TID 26)
[2023-01-30T11:12:59.795+0000] {spark_submit.py:495} INFO - 23/01/30 11:12:59 INFO CodeGenerator: Code generated in 69.686192 ms
[2023-01-30T11:13:00.100+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:00 INFO PythonRunner: Times: total = 453, boot = -7211, init = 7664, finish = 0
[2023-01-30T11:13:00.180+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:00 INFO Executor: Finished task 0.0 in stage 27.0 (TID 26). 2577 bytes result sent to driver
[2023-01-30T11:13:00.182+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:00 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 26) in 630 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:13:00.183+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:00 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2023-01-30T11:13:00.187+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:00 INFO DAGScheduler: ShuffleMapStage 27 (save at BigQueryWriteHelper.java:105) finished in 0.975 s
[2023-01-30T11:13:00.195+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:00 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:13:00.202+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:00 INFO DAGScheduler: running: HashSet()
[2023-01-30T11:13:00.203+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:00 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:13:00.203+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:00 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:13:01.038+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:01 INFO ShufflePartitionsUtil: For shuffle(17, 1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2023-01-30T11:13:02.571+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:02 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 5b6f5d29e531:35827 in memory (size: 9.2 KiB, free: 434.3 MiB)
[2023-01-30T11:13:03.749+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:03 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:13:03.900+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:03 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.3 MiB)
[2023-01-30T11:13:04.035+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:04 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 5b6f5d29e531:35827 in memory (size: 8.1 KiB, free: 434.4 MiB)
[2023-01-30T11:13:04.216+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:04 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 5b6f5d29e531:35827 in memory (size: 10.2 KiB, free: 434.4 MiB)
[2023-01-30T11:13:04.468+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:04 INFO CodeGenerator: Code generated in 211.820102 ms
[2023-01-30T11:13:04.667+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:04 INFO CodeGenerator: Code generated in 165.01688 ms
[2023-01-30T11:13:05.100+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO CodeGenerator: Code generated in 116.271113 ms
[2023-01-30T11:13:05.724+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2023-01-30T11:13:05.724+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO DAGScheduler: Got job 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2023-01-30T11:13:05.725+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO DAGScheduler: Final stage: ResultStage 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2023-01-30T11:13:05.725+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28, ShuffleMapStage 29)
[2023-01-30T11:13:05.725+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:13:05.735+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[163] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2023-01-30T11:13:05.743+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 48.6 KiB, free 433.1 MiB)
[2023-01-30T11:13:05.747+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 22.6 KiB, free 433.1 MiB)
[2023-01-30T11:13:05.748+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 5b6f5d29e531:35827 (size: 22.6 KiB, free: 434.3 MiB)
[2023-01-30T11:13:05.748+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:13:05.748+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[163] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:13:05.748+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
[2023-01-30T11:13:05.754+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 27) (5b6f5d29e531, executor driver, partition 0, NODE_LOCAL, 7897 bytes) taskResourceAssignments Map()
[2023-01-30T11:13:05.765+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:05 INFO Executor: Running task 0.0 in stage 30.0 (TID 27)
[2023-01-30T11:13:06.055+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO ShuffleBlockFetcherIterator: Getting 1 (288.0 B) non-empty blocks including 1 (288.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:06.056+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-01-30T11:13:06.115+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO CodeGenerator: Code generated in 51.068689 ms
[2023-01-30T11:13:06.179+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO CodeGenerator: Code generated in 47.779906 ms
[2023-01-30T11:13:06.184+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:06.185+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-01-30T11:13:06.319+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO CodeGenerator: Code generated in 77.432006 ms
[2023-01-30T11:13:06.393+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO CodeGenerator: Code generated in 51.643404 ms
[2023-01-30T11:13:06.596+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO Executor: Finished task 0.0 in stage 30.0 (TID 27). 6215 bytes result sent to driver
[2023-01-30T11:13:06.604+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 27) in 855 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:13:06.605+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2023-01-30T11:13:06.615+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO DAGScheduler: ResultStage 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.874 s
[2023-01-30T11:13:06.616+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:13:06.616+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
[2023-01-30T11:13:06.617+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO DAGScheduler: Job 27 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.887971 s
[2023-01-30T11:13:06.769+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO CodeGenerator: Code generated in 91.693215 ms
[2023-01-30T11:13:06.788+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 1024.1 KiB, free 432.1 MiB)
[2023-01-30T11:13:06.828+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 286.0 B, free 432.1 MiB)
[2023-01-30T11:13:06.830+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 5b6f5d29e531:35827 (size: 286.0 B, free: 434.3 MiB)
[2023-01-30T11:13:06.832+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:06 INFO SparkContext: Created broadcast 37 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2023-01-30T11:13:07.036+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:07 INFO ShufflePartitionsUtil: For shuffle(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2023-01-30T11:13:07.734+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:07 INFO CodeGenerator: Code generated in 307.514741 ms
[2023-01-30T11:13:08.589+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:08 INFO CodeGenerator: Code generated in 781.7083 ms
[2023-01-30T11:13:08.848+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:08 INFO CodeGenerator: Code generated in 185.640263 ms
[2023-01-30T11:13:09.076+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO CodeGenerator: Code generated in 181.797767 ms
[2023-01-30T11:13:09.119+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO CodeGenerator: Code generated in 26.142321 ms
[2023-01-30T11:13:09.190+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO CodeGenerator: Code generated in 67.880932 ms
[2023-01-30T11:13:09.277+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO CodeGenerator: Code generated in 65.038637 ms
[2023-01-30T11:13:09.517+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:13:09.519+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:13:09.522+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:13:09.534+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:13:09.534+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO BlockManager: Reporting 8 blocks to the master.
[2023-01-30T11:13:09.541+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO BlockManagerInfo: Updated broadcast_37_piece0 in memory on 5b6f5d29e531:35827 (current size: 286.0 B, original size: 286.0 B, free: 434.3 MiB)
[2023-01-30T11:13:09.576+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO BlockManagerInfo: Updated broadcast_36_piece0 in memory on 5b6f5d29e531:35827 (current size: 22.6 KiB, original size: 22.6 KiB, free: 434.3 MiB)
[2023-01-30T11:13:09.578+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:13:09.621+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO BlockManagerInfo: Updated broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (current size: 279.0 B, original size: 279.0 B, free: 434.3 MiB)
[2023-01-30T11:13:09.672+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO CodeGenerator: Code generated in 372.475831 ms
[2023-01-30T11:13:09.948+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:09 INFO CodeGenerator: Code generated in 220.003852 ms
[2023-01-30T11:13:10.458+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:10 INFO CodeGenerator: Code generated in 369.106931 ms
[2023-01-30T11:13:11.243+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:11 INFO CodeGenerator: Code generated in 661.01409 ms
[2023-01-30T11:13:11.267+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:11 INFO CodeGenerator: Code generated in 19.716184 ms
[2023-01-30T11:13:11.485+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:11 INFO CodeGenerator: Code generated in 212.364679 ms
[2023-01-30T11:13:11.781+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:11 INFO CodeGenerator: Code generated in 170.94287 ms
[2023-01-30T11:13:12.159+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:12 INFO CodeGenerator: Code generated in 350.115211 ms
[2023-01-30T11:13:12.164+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:12 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 5b6f5d29e531:35827 in memory (size: 22.6 KiB, free: 434.4 MiB)
[2023-01-30T11:13:12.975+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:12 INFO CodeGenerator: Code generated in 297.920382 ms
[2023-01-30T11:13:13.259+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:13 INFO CodeGenerator: Code generated in 37.762038 ms
[2023-01-30T11:13:13.726+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:13 INFO CodeGenerator: Code generated in 15.436884 ms
[2023-01-30T11:13:14.277+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:14 INFO CodeGenerator: Code generated in 236.859449 ms
[2023-01-30T11:13:14.405+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:14 INFO CodeGenerator: Code generated in 66.470591 ms
[2023-01-30T11:13:14.443+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:14 INFO CodeGenerator: Code generated in 11.693515 ms
[2023-01-30T11:13:14.512+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:14 INFO CodeGenerator: Code generated in 29.565238 ms
[2023-01-30T11:13:14.572+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:14 INFO CodeGenerator: Code generated in 15.453912 ms
[2023-01-30T11:13:14.620+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:14 INFO CodeGenerator: Code generated in 12.372042 ms
[2023-01-30T11:13:14.665+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:14 INFO CodeGenerator: Code generated in 17.62748 ms
[2023-01-30T11:13:14.712+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:14 INFO CodeGenerator: Code generated in 13.848826 ms
[2023-01-30T11:13:14.750+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:14 INFO CodeGenerator: Code generated in 14.946901 ms
[2023-01-30T11:13:14.947+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:14 INFO CodeGenerator: Code generated in 82.943405 ms
[2023-01-30T11:13:15.022+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:15 INFO CodeGenerator: Code generated in 14.706935 ms
[2023-01-30T11:13:15.185+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:15 INFO CodeGenerator: Code generated in 57.708409 ms
[2023-01-30T11:13:16.149+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO SparkContext: Starting job: save at BigQueryWriteHelper.java:105
[2023-01-30T11:13:16.194+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO DAGScheduler: Got job 28 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:13:16.196+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO DAGScheduler: Final stage: ResultStage 46 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:13:16.197+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 31)
[2023-01-30T11:13:16.197+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:13:16.223+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[224] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:13:16.711+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 276.3 KiB, free 431.9 MiB)
[2023-01-30T11:13:16.777+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 84.6 KiB, free 431.8 MiB)
[2023-01-30T11:13:16.780+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 5b6f5d29e531:35827 (size: 84.6 KiB, free: 434.3 MiB)
[2023-01-30T11:13:16.780+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:13:16.781+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[224] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:13:16.781+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2023-01-30T11:13:16.792+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 28) (5b6f5d29e531, executor driver, partition 0, NODE_LOCAL, 8781 bytes) taskResourceAssignments Map()
[2023-01-30T11:13:16.793+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO Executor: Running task 0.0 in stage 46.0 (TID 28)
[2023-01-30T11:13:16.910+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:16.910+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2023-01-30T11:13:16.935+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:16.936+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:16.950+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:16.950+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:16.964+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:16.964+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:16.983+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:16.984+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-01-30T11:13:17.429+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:17.430+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-01-30T11:13:17.559+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:17.559+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:17.581+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:17.583+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2023-01-30T11:13:17.609+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:17.609+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-01-30T11:13:17.700+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:17.702+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2023-01-30T11:13:17.723+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:17.723+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:17.752+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:17.753+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:17.763+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:17.763+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:17.777+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:17.777+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:17.793+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:17.799+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2023-01-30T11:13:17.826+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:17 INFO CodeGenerator: Code generated in 11.880426 ms
[2023-01-30T11:13:19.091+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO Executor: Finished task 0.0 in stage 46.0 (TID 28). 25165 bytes result sent to driver
[2023-01-30T11:13:19.097+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 28) in 2310 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:13:19.097+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2023-01-30T11:13:19.105+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO DAGScheduler: ResultStage 46 (save at BigQueryWriteHelper.java:105) finished in 2.873 s
[2023-01-30T11:13:19.106+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:13:19.106+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
[2023-01-30T11:13:19.111+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO DAGScheduler: Job 28 finished: save at BigQueryWriteHelper.java:105, took 2.952219 s
[2023-01-30T11:13:19.205+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO DAGScheduler: Registering RDD 225 (save at BigQueryWriteHelper.java:105) as input to shuffle 18
[2023-01-30T11:13:19.205+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO DAGScheduler: Got map stage job 29 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:13:19.205+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:13:19.206+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ShuffleMapStage 55, ShuffleMapStage 56, ShuffleMapStage 57, ShuffleMapStage 58, ShuffleMapStage 59, ShuffleMapStage 60, ShuffleMapStage 61)
[2023-01-30T11:13:19.208+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:13:19.269+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[225] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:13:19.492+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:13:19.492+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:13:19.492+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:13:19.506+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:13:19.506+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO BlockManager: Reporting 8 blocks to the master.
[2023-01-30T11:13:19.509+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO BlockManagerInfo: Updated broadcast_37_piece0 in memory on 5b6f5d29e531:35827 (current size: 286.0 B, original size: 286.0 B, free: 434.3 MiB)
[2023-01-30T11:13:19.510+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:13:19.511+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO BlockManagerInfo: Updated broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (current size: 279.0 B, original size: 279.0 B, free: 434.3 MiB)
[2023-01-30T11:13:19.517+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO BlockManagerInfo: Updated broadcast_38_piece0 in memory on 5b6f5d29e531:35827 (current size: 84.6 KiB, original size: 84.6 KiB, free: 434.3 MiB)
[2023-01-30T11:13:19.517+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 276.2 KiB, free 431.5 MiB)
[2023-01-30T11:13:19.572+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 84.6 KiB, free 431.5 MiB)
[2023-01-30T11:13:19.572+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 5b6f5d29e531:35827 (size: 84.6 KiB, free: 434.2 MiB)
[2023-01-30T11:13:19.576+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:13:19.578+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[225] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:13:19.590+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
[2023-01-30T11:13:19.591+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 29) (5b6f5d29e531, executor driver, partition 0, NODE_LOCAL, 8770 bytes) taskResourceAssignments Map()
[2023-01-30T11:13:19.591+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:19 INFO Executor: Running task 0.0 in stage 62.0 (TID 29)
[2023-01-30T11:13:20.353+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.354+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:20.398+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.398+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-01-30T11:13:20.462+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.463+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:20.518+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.559+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-01-30T11:13:20.609+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.609+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 37 ms
[2023-01-30T11:13:20.639+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.668+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:20.707+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.707+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:20.719+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.719+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:20.766+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.767+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:20.811+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.811+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:20.855+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.856+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2023-01-30T11:13:20.863+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.864+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2023-01-30T11:13:20.924+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:20.925+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:21.020+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:21.021+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:21.085+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:21.090+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 58 ms
[2023-01-30T11:13:21.414+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO Executor: Finished task 0.0 in stage 62.0 (TID 29). 25027 bytes result sent to driver
[2023-01-30T11:13:21.419+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 29) in 1830 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:13:21.434+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2023-01-30T11:13:21.446+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO DAGScheduler: ShuffleMapStage 62 (save at BigQueryWriteHelper.java:105) finished in 2.159 s
[2023-01-30T11:13:21.446+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO DAGScheduler: looking for newly runnable stages
[2023-01-30T11:13:21.446+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO DAGScheduler: running: HashSet()
[2023-01-30T11:13:21.447+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO DAGScheduler: waiting: HashSet()
[2023-01-30T11:13:21.447+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO DAGScheduler: failed: HashSet()
[2023-01-30T11:13:21.507+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:21 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2023-01-30T11:13:22.192+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:22 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 5b6f5d29e531:35827 in memory (size: 84.6 KiB, free: 434.3 MiB)
[2023-01-30T11:13:22.379+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:22 INFO CodeGenerator: Code generated in 382.354485 ms
[2023-01-30T11:13:22.897+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:22 INFO SparkContext: Starting job: save at BigQueryWriteHelper.java:105
[2023-01-30T11:13:22.911+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:22 INFO DAGScheduler: Got job 30 (save at BigQueryWriteHelper.java:105) with 1 output partitions
[2023-01-30T11:13:22.911+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:22 INFO DAGScheduler: Final stage: ResultStage 79 (save at BigQueryWriteHelper.java:105)
[2023-01-30T11:13:22.912+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
[2023-01-30T11:13:22.912+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:22 INFO DAGScheduler: Missing parents: List()
[2023-01-30T11:13:22.931+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:22 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[227] at save at BigQueryWriteHelper.java:105), which has no missing parents
[2023-01-30T11:13:23.205+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:23 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 354.4 KiB, free 431.5 MiB)
[2023-01-30T11:13:23.236+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:23 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 110.5 KiB, free 431.4 MiB)
[2023-01-30T11:13:23.237+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:23 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 5b6f5d29e531:35827 (size: 110.5 KiB, free: 434.2 MiB)
[2023-01-30T11:13:23.245+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:23 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1513
[2023-01-30T11:13:23.251+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[227] at save at BigQueryWriteHelper.java:105) (first 15 tasks are for partitions Vector(0))
[2023-01-30T11:13:23.251+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:23 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0
[2023-01-30T11:13:23.261+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:23 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 30) (5b6f5d29e531, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
[2023-01-30T11:13:23.267+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:23 INFO Executor: Running task 0.0 in stage 79.0 (TID 30)
[2023-01-30T11:13:23.836+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:23 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 5b6f5d29e531:35827 in memory (size: 84.6 KiB, free: 434.3 MiB)
[2023-01-30T11:13:24.127+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO ShuffleBlockFetcherIterator: Getting 1 (568.0 B) non-empty blocks including 1 (568.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-01-30T11:13:24.127+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-01-30T11:13:24.327+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO CodeGenerator: Code generated in 130.674299 ms
[2023-01-30T11:13:24.372+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-01-30T11:13:24.372+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-01-30T11:13:24.377+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-01-30T11:13:24.378+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-01-30T11:13:24.378+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-01-30T11:13:24.378+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-01-30T11:13:24.445+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO CodecConfig: Compression: SNAPPY
[2023-01-30T11:13:24.516+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO CodecConfig: Compression: SNAPPY
[2023-01-30T11:13:24.880+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO ParquetOutputFormat: Parquet block size to 134217728
[2023-01-30T11:13:24.880+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO ParquetOutputFormat: Validation is off
[2023-01-30T11:13:24.881+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
[2023-01-30T11:13:24.881+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:24 INFO ParquetOutputFormat: Parquet properties are:
[2023-01-30T11:13:24.881+0000] {spark_submit.py:495} INFO - Parquet page size to 1048576
[2023-01-30T11:13:24.881+0000] {spark_submit.py:495} INFO - Parquet dictionary page size to 1048576
[2023-01-30T11:13:24.881+0000] {spark_submit.py:495} INFO - Dictionary is true
[2023-01-30T11:13:24.881+0000] {spark_submit.py:495} INFO - Writer version is: PARQUET_1_0
[2023-01-30T11:13:24.882+0000] {spark_submit.py:495} INFO - Page size checking is: estimated
[2023-01-30T11:13:24.882+0000] {spark_submit.py:495} INFO - Min row count for page size check is: 100
[2023-01-30T11:13:24.882+0000] {spark_submit.py:495} INFO - Max row count for page size check is: 10000
[2023-01-30T11:13:24.882+0000] {spark_submit.py:495} INFO - Truncate length for column indexes is: 64
[2023-01-30T11:13:24.882+0000] {spark_submit.py:495} INFO - Truncate length for statistics min/max  is: 2147483647
[2023-01-30T11:13:24.882+0000] {spark_submit.py:495} INFO - Bloom filter enabled: false
[2023-01-30T11:13:24.882+0000] {spark_submit.py:495} INFO - Max Bloom filter size for a column is 1048576
[2023-01-30T11:13:24.883+0000] {spark_submit.py:495} INFO - Bloom filter expected number of distinct values are: null
[2023-01-30T11:13:24.883+0000] {spark_submit.py:495} INFO - Page row count limit to 20000
[2023-01-30T11:13:24.883+0000] {spark_submit.py:495} INFO - Writing page checksums is: on
[2023-01-30T11:13:25.307+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:25 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-01-30T11:13:25.307+0000] {spark_submit.py:495} INFO - {
[2023-01-30T11:13:25.307+0000] {spark_submit.py:495} INFO - "type" : "struct",
[2023-01-30T11:13:25.307+0000] {spark_submit.py:495} INFO - "fields" : [ {
[2023-01-30T11:13:25.308+0000] {spark_submit.py:495} INFO - "name" : "measured_at",
[2023-01-30T11:13:25.308+0000] {spark_submit.py:495} INFO - "type" : "timestamp",
[2023-01-30T11:13:25.308+0000] {spark_submit.py:495} INFO - "nullable" : false,
[2023-01-30T11:13:25.308+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.308+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.308+0000] {spark_submit.py:495} INFO - "name" : "created_at",
[2023-01-30T11:13:25.308+0000] {spark_submit.py:495} INFO - "type" : "timestamp",
[2023-01-30T11:13:25.308+0000] {spark_submit.py:495} INFO - "nullable" : false,
[2023-01-30T11:13:25.309+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.309+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.309+0000] {spark_submit.py:495} INFO - "name" : "Biomass - Actual Aggregated",
[2023-01-30T11:13:25.309+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.309+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.309+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.309+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.310+0000] {spark_submit.py:495} INFO - "name" : "Fossil Brown coal/Lignite - Actual Aggregated",
[2023-01-30T11:13:25.310+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.310+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.310+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.310+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.310+0000] {spark_submit.py:495} INFO - "name" : "Fossil Gas - Actual Aggregated",
[2023-01-30T11:13:25.310+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.310+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.311+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.311+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.311+0000] {spark_submit.py:495} INFO - "name" : "Fossil Hard coal - Actual Aggregated",
[2023-01-30T11:13:25.311+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.312+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.313+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.313+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.313+0000] {spark_submit.py:495} INFO - "name" : "Fossil Oil - Actual Aggregated",
[2023-01-30T11:13:25.313+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.313+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.313+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.313+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.314+0000] {spark_submit.py:495} INFO - "name" : "Geothermal - Actual Aggregated",
[2023-01-30T11:13:25.314+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.314+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.314+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.314+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.314+0000] {spark_submit.py:495} INFO - "name" : "Hydro Pumped Storage - Actual Aggregated",
[2023-01-30T11:13:25.314+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.315+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.315+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.315+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.315+0000] {spark_submit.py:495} INFO - "name" : "Hydro Pumped Storage - Actual Consumption",
[2023-01-30T11:13:25.323+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.323+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.324+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.324+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.324+0000] {spark_submit.py:495} INFO - "name" : "Hydro Run-of-river and poundage - Actual Aggregated",
[2023-01-30T11:13:25.324+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.324+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.324+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.325+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.325+0000] {spark_submit.py:495} INFO - "name" : "Hydro Water Reservoir - Actual Aggregated",
[2023-01-30T11:13:25.325+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.325+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.325+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.325+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.326+0000] {spark_submit.py:495} INFO - "name" : "Nuclear - Actual Aggregated",
[2023-01-30T11:13:25.326+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.326+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.326+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.326+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.326+0000] {spark_submit.py:495} INFO - "name" : "Other - Actual Aggregated",
[2023-01-30T11:13:25.326+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.327+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.327+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.327+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.330+0000] {spark_submit.py:495} INFO - "name" : "Other renewable - Actual Aggregated",
[2023-01-30T11:13:25.330+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.331+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.331+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.331+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.331+0000] {spark_submit.py:495} INFO - "name" : "Solar - Actual Aggregated",
[2023-01-30T11:13:25.341+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.341+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.342+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.342+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.342+0000] {spark_submit.py:495} INFO - "name" : "Waste - Actual Aggregated",
[2023-01-30T11:13:25.342+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.342+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.342+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.342+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.343+0000] {spark_submit.py:495} INFO - "name" : "Wind Offshore - Actual Aggregated",
[2023-01-30T11:13:25.343+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.343+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.343+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.343+0000] {spark_submit.py:495} INFO - }, {
[2023-01-30T11:13:25.343+0000] {spark_submit.py:495} INFO - "name" : "Wind Onshore - Actual Aggregated",
[2023-01-30T11:13:25.343+0000] {spark_submit.py:495} INFO - "type" : "double",
[2023-01-30T11:13:25.344+0000] {spark_submit.py:495} INFO - "nullable" : true,
[2023-01-30T11:13:25.344+0000] {spark_submit.py:495} INFO - "metadata" : { }
[2023-01-30T11:13:25.344+0000] {spark_submit.py:495} INFO - } ]
[2023-01-30T11:13:25.344+0000] {spark_submit.py:495} INFO - }
[2023-01-30T11:13:25.344+0000] {spark_submit.py:495} INFO - and corresponding Parquet message type:
[2023-01-30T11:13:25.344+0000] {spark_submit.py:495} INFO - message spark_schema {
[2023-01-30T11:13:25.344+0000] {spark_submit.py:495} INFO - required int96 measured_at;
[2023-01-30T11:13:25.345+0000] {spark_submit.py:495} INFO - required int96 created_at;
[2023-01-30T11:13:25.345+0000] {spark_submit.py:495} INFO - optional double Biomass - Actual Aggregated;
[2023-01-30T11:13:25.345+0000] {spark_submit.py:495} INFO - optional double Fossil Brown coal/Lignite - Actual Aggregated;
[2023-01-30T11:13:25.345+0000] {spark_submit.py:495} INFO - optional double Fossil Gas - Actual Aggregated;
[2023-01-30T11:13:25.345+0000] {spark_submit.py:495} INFO - optional double Fossil Hard coal - Actual Aggregated;
[2023-01-30T11:13:25.345+0000] {spark_submit.py:495} INFO - optional double Fossil Oil - Actual Aggregated;
[2023-01-30T11:13:25.345+0000] {spark_submit.py:495} INFO - optional double Geothermal - Actual Aggregated;
[2023-01-30T11:13:25.345+0000] {spark_submit.py:495} INFO - optional double Hydro Pumped Storage - Actual Aggregated;
[2023-01-30T11:13:25.346+0000] {spark_submit.py:495} INFO - optional double Hydro Pumped Storage - Actual Consumption;
[2023-01-30T11:13:25.346+0000] {spark_submit.py:495} INFO - optional double Hydro Run-of-river and poundage - Actual Aggregated;
[2023-01-30T11:13:25.346+0000] {spark_submit.py:495} INFO - optional double Hydro Water Reservoir - Actual Aggregated;
[2023-01-30T11:13:25.346+0000] {spark_submit.py:495} INFO - optional double Nuclear - Actual Aggregated;
[2023-01-30T11:13:25.346+0000] {spark_submit.py:495} INFO - optional double Other - Actual Aggregated;
[2023-01-30T11:13:25.346+0000] {spark_submit.py:495} INFO - optional double Other renewable - Actual Aggregated;
[2023-01-30T11:13:25.346+0000] {spark_submit.py:495} INFO - optional double Solar - Actual Aggregated;
[2023-01-30T11:13:25.347+0000] {spark_submit.py:495} INFO - optional double Waste - Actual Aggregated;
[2023-01-30T11:13:25.347+0000] {spark_submit.py:495} INFO - optional double Wind Offshore - Actual Aggregated;
[2023-01-30T11:13:25.347+0000] {spark_submit.py:495} INFO - optional double Wind Onshore - Actual Aggregated;
[2023-01-30T11:13:25.347+0000] {spark_submit.py:495} INFO - }
[2023-01-30T11:13:25.347+0000] {spark_submit.py:495} INFO - 
[2023-01-30T11:13:25.347+0000] {spark_submit.py:495} INFO - 
[2023-01-30T11:13:27.914+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:27 INFO CodecPool: Got brand-new compressor [.snappy]
[2023-01-30T11:13:29.807+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:29 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:13:29.808+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:29 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:13:29.808+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:13:29.817+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:13:29.818+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:29 INFO BlockManager: Reporting 8 blocks to the master.
[2023-01-30T11:13:29.823+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:29 INFO BlockManagerInfo: Updated broadcast_37_piece0 in memory on 5b6f5d29e531:35827 (current size: 286.0 B, original size: 286.0 B, free: 434.3 MiB)
[2023-01-30T11:13:29.847+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:29 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:13:29.857+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:29 INFO BlockManagerInfo: Updated broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (current size: 279.0 B, original size: 279.0 B, free: 434.3 MiB)
[2023-01-30T11:13:29.864+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:29 INFO BlockManagerInfo: Updated broadcast_40_piece0 in memory on 5b6f5d29e531:35827 (current size: 110.5 KiB, original size: 110.5 KiB, free: 434.3 MiB)
[2023-01-30T11:13:39.497+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:39 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:13:39.499+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:39 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:13:39.499+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:13:39.500+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:13:39.500+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:39 INFO BlockManager: Reporting 8 blocks to the master.
[2023-01-30T11:13:39.504+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:39 INFO BlockManagerInfo: Updated broadcast_37_piece0 in memory on 5b6f5d29e531:35827 (current size: 286.0 B, original size: 286.0 B, free: 434.3 MiB)
[2023-01-30T11:13:39.510+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:39 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:13:39.520+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:39 INFO BlockManagerInfo: Updated broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (current size: 279.0 B, original size: 279.0 B, free: 434.3 MiB)
[2023-01-30T11:13:39.523+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:39 INFO BlockManagerInfo: Updated broadcast_40_piece0 in memory on 5b6f5d29e531:35827 (current size: 110.5 KiB, original size: 110.5 KiB, free: 434.3 MiB)
[2023-01-30T11:13:46.517+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://entsoe_temp_1009/.spark-bigquery-local-1675076652356-b275c93f-dcf0-41cf-8b61-fe652dea1f47/_temporary/0/_temporary/' directory.
[2023-01-30T11:13:46.542+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO FileOutputCommitter: Saved output of task 'attempt_202301301113223650116779524006748_0079_m_000000_30' to gs://entsoe_temp_1009/.spark-bigquery-local-1675076652356-b275c93f-dcf0-41cf-8b61-fe652dea1f47/_temporary/0/task_202301301113223650116779524006748_0079_m_000000
[2023-01-30T11:13:46.542+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO SparkHadoopMapRedUtil: attempt_202301301113223650116779524006748_0079_m_000000_30: Committed. Elapsed time: 3009 ms.
[2023-01-30T11:13:46.651+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO Executor: Finished task 0.0 in stage 79.0 (TID 30). 26967 bytes result sent to driver
[2023-01-30T11:13:46.656+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 30) in 23397 ms on 5b6f5d29e531 (executor driver) (1/1)
[2023-01-30T11:13:46.659+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2023-01-30T11:13:46.667+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO DAGScheduler: ResultStage 79 (save at BigQueryWriteHelper.java:105) finished in 23.723 s
[2023-01-30T11:13:46.668+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-01-30T11:13:46.668+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
[2023-01-30T11:13:46.669+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO DAGScheduler: Job 30 finished: save at BigQueryWriteHelper.java:105, took 23.768996 s
[2023-01-30T11:13:46.680+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:46 INFO FileFormatWriter: Start to commit write Job 2039c487-a3a0-435f-ae97-cf59c43b37f2.
[2023-01-30T11:13:47.858+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:47 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://entsoe_temp_1009/.spark-bigquery-local-1675076652356-b275c93f-dcf0-41cf-8b61-fe652dea1f47/_temporary/0/task_202301301113223650116779524006748_0079_m_000000/' directory.
[2023-01-30T11:13:48.832+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:48 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://entsoe_temp_1009/.spark-bigquery-local-1675076652356-b275c93f-dcf0-41cf-8b61-fe652dea1f47/' directory.
[2023-01-30T11:13:49.495+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:49 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:13:49.503+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:49 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:13:49.504+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:13:49.504+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:13:49.505+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:49 INFO BlockManager: Reporting 8 blocks to the master.
[2023-01-30T11:13:49.505+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:49 INFO BlockManagerInfo: Updated broadcast_37_piece0 in memory on 5b6f5d29e531:35827 (current size: 286.0 B, original size: 286.0 B, free: 434.3 MiB)
[2023-01-30T11:13:49.505+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:49 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.3 MiB)
[2023-01-30T11:13:49.514+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:49 INFO BlockManagerInfo: Updated broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (current size: 279.0 B, original size: 279.0 B, free: 434.3 MiB)
[2023-01-30T11:13:49.518+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:49 INFO BlockManagerInfo: Updated broadcast_40_piece0 in memory on 5b6f5d29e531:35827 (current size: 110.5 KiB, original size: 110.5 KiB, free: 434.3 MiB)
[2023-01-30T11:13:50.252+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:50 INFO FileFormatWriter: Write Job 2039c487-a3a0-435f-ae97-cf59c43b37f2 committed. Elapsed time: 3553 ms.
[2023-01-30T11:13:50.665+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:50 INFO FileFormatWriter: Finished processing stats for write job 2039c487-a3a0-435f-ae97-cf59c43b37f2.
[2023-01-30T11:13:50.950+0000] {spark_submit.py:495} INFO - 23/01/30 11:13:50 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 5b6f5d29e531:35827 in memory (size: 110.5 KiB, free: 434.4 MiB)
[2023-01-30T11:14:01.605+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:01 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:14:01.845+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:01 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:14:01.846+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:14:01.914+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:14:01.914+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:01 INFO BlockManager: Reporting 6 blocks to the master.
[2023-01-30T11:14:02.679+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:02 INFO BlockManagerInfo: Updated broadcast_37_piece0 in memory on 5b6f5d29e531:35827 (current size: 286.0 B, original size: 286.0 B, free: 434.4 MiB)
[2023-01-30T11:14:03.432+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:03 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.4 MiB)
[2023-01-30T11:14:04.320+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:04 INFO BlockManagerInfo: Updated broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (current size: 279.0 B, original size: 279.0 B, free: 434.4 MiB)
[2023-01-30T11:14:12.399+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:12 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:14:12.424+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:12 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:14:12.424+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:14:12.429+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:14:12.429+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:12 INFO BlockManager: Reporting 6 blocks to the master.
[2023-01-30T11:14:12.505+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:12 INFO BlockManagerInfo: Updated broadcast_37_piece0 in memory on 5b6f5d29e531:35827 (current size: 286.0 B, original size: 286.0 B, free: 434.4 MiB)
[2023-01-30T11:14:12.512+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:12 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.4 MiB)
[2023-01-30T11:14:12.560+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:12 INFO BlockManagerInfo: Updated broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (current size: 279.0 B, original size: 279.0 B, free: 434.4 MiB)
[2023-01-30T11:14:19.504+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:19 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:14:19.508+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:19 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:14:19.508+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:14:19.509+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:14:19.510+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:19 INFO BlockManager: Reporting 6 blocks to the master.
[2023-01-30T11:14:19.524+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:19 INFO BlockManagerInfo: Updated broadcast_37_piece0 in memory on 5b6f5d29e531:35827 (current size: 286.0 B, original size: 286.0 B, free: 434.4 MiB)
[2023-01-30T11:14:19.543+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:19 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.4 MiB)
[2023-01-30T11:14:19.575+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:19 INFO BlockManagerInfo: Updated broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (current size: 279.0 B, original size: 279.0 B, free: 434.4 MiB)
[2023-01-30T11:14:21.012+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:20 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=entsoe_analytics_1009, projectId=rafzul-analytics-1009, tableId=TEST_total_generation_staging}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=null, ignoreUnknownValue=null, sourceUris=[gs://entsoe_temp_1009/.spark-bigquery-local-1675076652356-b275c93f-dcf0-41cf-8b61-fe652dea1f47/part-00000-9b8a2463-7fb2-4296-953a-ae710e57f0f7-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=true, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=rafzul-analytics-1009, job=9c0d12b2-6c43-4030-b68d-a4ae9264dfcc, location=US}
[2023-01-30T11:14:29.250+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:29 INFO BigQueryClient: Done loading to rafzul-analytics-1009.entsoe_analytics_1009.TEST_total_generation_staging. jobId: JobId{project=rafzul-analytics-1009, job=9c0d12b2-6c43-4030-b68d-a4ae9264dfcc, location=US}
[2023-01-30T11:14:30.473+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:30 INFO Executor: Told to re-register on heartbeat
[2023-01-30T11:14:30.503+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:30 INFO BlockManager: BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None) re-registering with master
[2023-01-30T11:14:30.504+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:14:30.504+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 5b6f5d29e531, 35827, None)
[2023-01-30T11:14:30.527+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:30 INFO BlockManager: Reporting 6 blocks to the master.
[2023-01-30T11:14:30.693+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:30 INFO BlockManagerInfo: Updated broadcast_37_piece0 in memory on 5b6f5d29e531:35827 (current size: 286.0 B, original size: 286.0 B, free: 434.4 MiB)
[2023-01-30T11:14:30.759+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:30 INFO BlockManagerInfo: Updated broadcast_2_piece0 in memory on 5b6f5d29e531:35827 (current size: 34.5 KiB, original size: 34.5 KiB, free: 434.4 MiB)
[2023-01-30T11:14:30.770+0000] {spark_submit.py:495} INFO - 23/01/30 11:14:30 INFO BlockManagerInfo: Updated broadcast_34_piece0 in memory on 5b6f5d29e531:35827 (current size: 279.0 B, original size: 279.0 B, free: 434.4 MiB)
